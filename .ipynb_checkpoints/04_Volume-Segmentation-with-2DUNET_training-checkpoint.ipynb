{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jain0000/miniconda3/envs/segment2/lib/python3.7/site-packages/dicom/__init__.py:53: UserWarning: \n",
      "This code is using an older version of pydicom, which is no longer \n",
      "maintained as of Jan 2017.  You can access the new pydicom features and API \n",
      "by installing `pydicom` from PyPI.\n",
      "See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org \n",
      "for more information.\n",
      "\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from niwidgets import NiftiWidget\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import * \n",
    "from tensorflow import keras\n",
    "from config import *\n",
    "from modelIO import *\n",
    "from model import *\n",
    "from segmentation import *\n",
    "from display import *\n",
    "from dataAugmentation import *\n",
    "import math\n",
    "import random\n",
    "from skimage.util import montage, crop\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.metrics import MeanIoU,BinaryCrossentropy,Accuracy,Precision,Recall\n",
    "from skimage.transform import rescale, resize, downscale_local_mean,rotate\n",
    "from skimage import data, color\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "from numpy import fliplr\n",
    "from PIL import Image\n",
    "from datetime import *\n",
    "from sklearn.model_selection import KFold\n",
    "#print(device_lib.list_local_devices())\n",
    "#tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 40, 40, 40) (10, 40, 40, 40)\n"
     ]
    }
   ],
   "source": [
    "(train_images,train_labels,test_images,test_labels) = load_data('segmentation2d',\n",
    "           unet2d(4),TYPE)\n",
    "print(train_images.shape,train_labels.shape)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function train_preprocessing at 0x7f2223278170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function train_preprocessing at 0x7f2223278170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function data_aug at 0x7f22a8702c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function data_aug at 0x7f22a8702c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function fixup_shape at 0x7f2223278290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function fixup_shape at 0x7f2223278290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function validation_preprocessing at 0x7f2223278200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function validation_preprocessing at 0x7f2223278200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((test_images,test_labels))\n",
    "    \n",
    "train_dataset = (\n",
    "train_loader\n",
    ".shuffle(train_dataset_batch_size)\n",
    ".map(train_preprocessing)\n",
    ".map(fixup_shape)\n",
    ".batch(train_dataset_batch_size)  \n",
    ".prefetch(train_dataset_batch_size)\n",
    ")\n",
    "# Only rescale.\n",
    "validation_dataset = (\n",
    "    validation_loader\n",
    "    .map(validation_preprocessing)\n",
    "    .map(fixup_shape)\n",
    "    .batch(test_dataset_batch_size)\n",
    "    .prefetch(test_dataset_batch_size)\n",
    ")\n",
    "      \n",
    "num = 5\n",
    "data = train_dataset.take(5)\n",
    "showDataset(data, num)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNET-L4-F32\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 40, 40, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 40, 40, 32)   320         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 40, 40, 32)   128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 40, 40, 32)   9248        batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 40, 40, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 20, 20, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 20, 20, 64)   18496       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 20, 20, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 20, 20, 64)   36928       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 20, 20, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 10, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 10, 10, 128)  73856       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 10, 10, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 10, 10, 128)  147584      batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 10, 10, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 5, 5, 128)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 5, 5, 256)    295168      max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 5, 5, 256)    1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 5, 5, 256)    590080      batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 5, 5, 256)    1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 10, 10, 128)  295040      batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 10, 10, 128)  512         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 10, 10, 256)  0           batch_normalization_19[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 10, 10, 128)  295040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 10, 10, 128)  147584      conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 20, 20, 64)   73792       conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 20, 20, 64)   256         conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 20, 20, 128)  0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 20, 20, 64)   73792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 20, 20, 64)   36928       conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 40, 40, 32)   18464       conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 40, 40, 32)   128         conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 40, 40, 64)   0           batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 40, 40, 32)   18464       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 40, 40, 32)   9248        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 40, 40, 32)   0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 40, 40, 1)    33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,144,801\n",
      "Trainable params: 2,142,433\n",
      "Non-trainable params: 2,368\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= get_model('segmentation2d')\n",
    "model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = LR_RATE\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "initial_learning_rate, decay_steps=100, decay_rate=0.9, staircase=True) \n",
    "loss_fn = Dice()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "name  = '-'.join(['UNET3D-Tooth','segmentation2d',str(IMAGE_HEIGHT),str(IMAGE_WIDTH),str(IMAGE_DEPTH),datetime.now().strftime(\"%Y%m%d-%H%M%S\"),'.h5'])   \n",
    "logdir = LOG_PATH + name\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f21101b2c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f21101b2c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.8502WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f207c41c680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f207c41c680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 1s 871ms/step - loss: 0.1099 - accuracy: 0.8502 - val_loss: 0.1829 - val_accuracy: 0.8637\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.8566WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.486696). Check your callbacks.\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0712 - accuracy: 0.8566 - val_loss: 0.1834 - val_accuracy: 0.8552\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0474 - accuracy: 0.8904 - val_loss: 0.1829 - val_accuracy: 0.8542\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0429 - accuracy: 0.8777 - val_loss: 0.1828 - val_accuracy: 0.8533\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0374 - accuracy: 0.8864 - val_loss: 0.1825 - val_accuracy: 0.8535\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0420 - accuracy: 0.8765 - val_loss: 0.1823 - val_accuracy: 0.8526\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0381 - accuracy: 0.8977 - val_loss: 0.1807 - val_accuracy: 0.8475\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.0372 - accuracy: 0.9013 - val_loss: 0.1778 - val_accuracy: 0.8281\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.0349 - accuracy: 0.9038 - val_loss: 0.1754 - val_accuracy: 0.8079\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.0223 - accuracy: 0.9530 - val_loss: 0.1714 - val_accuracy: 0.7923\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0257 - accuracy: 0.9404 - val_loss: 0.1646 - val_accuracy: 0.8219\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0315 - accuracy: 0.9180 - val_loss: 0.1586 - val_accuracy: 0.8107\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0169 - accuracy: 0.9635 - val_loss: 0.1510 - val_accuracy: 0.8216\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.0301 - accuracy: 0.9294 - val_loss: 0.1412 - val_accuracy: 0.8551\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.0245 - accuracy: 0.9405 - val_loss: 0.1306 - val_accuracy: 0.8839\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0206 - accuracy: 0.9512 - val_loss: 0.1198 - val_accuracy: 0.8965\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0194 - accuracy: 0.9524 - val_loss: 0.1102 - val_accuracy: 0.8802\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0263 - accuracy: 0.9380 - val_loss: 0.1008 - val_accuracy: 0.8706\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0253 - accuracy: 0.9387 - val_loss: 0.0914 - val_accuracy: 0.8680\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.0182 - accuracy: 0.9577 - val_loss: 0.0836 - val_accuracy: 0.8669\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.0155 - accuracy: 0.9624 - val_loss: 0.0773 - val_accuracy: 0.8666\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0213 - accuracy: 0.9514 - val_loss: 0.0714 - val_accuracy: 0.8666\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0210 - accuracy: 0.9481 - val_loss: 0.0668 - val_accuracy: 0.8666\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0223 - accuracy: 0.9406 - val_loss: 0.0632 - val_accuracy: 0.8666\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0147 - accuracy: 0.9654 - val_loss: 0.0604 - val_accuracy: 0.8666\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.0143 - accuracy: 0.9671 - val_loss: 0.0585 - val_accuracy: 0.8666\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0143 - accuracy: 0.9652 - val_loss: 0.0574 - val_accuracy: 0.8666\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0128 - accuracy: 0.9713 - val_loss: 0.0571 - val_accuracy: 0.8666\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0151 - accuracy: 0.9644 - val_loss: 0.0569 - val_accuracy: 0.8666\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0115 - accuracy: 0.9727 - val_loss: 0.0569 - val_accuracy: 0.8666\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0149 - accuracy: 0.9624 - val_loss: 0.0561 - val_accuracy: 0.8666\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0193 - accuracy: 0.9513 - val_loss: 0.0547 - val_accuracy: 0.8666\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.0168 - accuracy: 0.9574 - val_loss: 0.0533 - val_accuracy: 0.8666\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0176 - accuracy: 0.9587 - val_loss: 0.0541 - val_accuracy: 0.8666\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0184 - accuracy: 0.9577 - val_loss: 0.0575 - val_accuracy: 0.8666\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0143 - accuracy: 0.9661 - val_loss: 0.0607 - val_accuracy: 0.8666\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.0141 - accuracy: 0.9674 - val_loss: 0.0626 - val_accuracy: 0.8666\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0158 - accuracy: 0.9633 - val_loss: 0.0630 - val_accuracy: 0.8666\n",
      "Epoch 39/2000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.0133 - accuracy: 0.9654 - val_loss: 0.0630 - val_accuracy: 0.8666\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0123 - accuracy: 0.9704 - val_loss: 0.0627 - val_accuracy: 0.8666\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0111 - accuracy: 0.9737 - val_loss: 0.0624 - val_accuracy: 0.8666\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0171 - accuracy: 0.9582 - val_loss: 0.0622 - val_accuracy: 0.8666\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0120 - accuracy: 0.9704 - val_loss: 0.0622 - val_accuracy: 0.8666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/2000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0108 - accuracy: 0.9750 - val_loss: 0.0626 - val_accuracy: 0.8666\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.0130 - accuracy: 0.9685 - val_loss: 0.0627 - val_accuracy: 0.8666\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0117 - accuracy: 0.9713 - val_loss: 0.0627 - val_accuracy: 0.8666\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0111 - accuracy: 0.9741 - val_loss: 0.0629 - val_accuracy: 0.8666\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.0079 - accuracy: 0.9815 - val_loss: 0.0629 - val_accuracy: 0.8666\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0107 - accuracy: 0.9753 - val_loss: 0.0629 - val_accuracy: 0.8666\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0107 - accuracy: 0.9749 - val_loss: 0.0626 - val_accuracy: 0.8666\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.0115 - accuracy: 0.9729 - val_loss: 0.0620 - val_accuracy: 0.8666\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0118 - accuracy: 0.9702 - val_loss: 0.0611 - val_accuracy: 0.8666\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.0088 - accuracy: 0.9796 - val_loss: 0.0606 - val_accuracy: 0.8666\n",
      "Epoch 54/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0099 - accuracy: 0.9750 - val_loss: 0.0605 - val_accuracy: 0.8666\n",
      "Epoch 55/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0135 - accuracy: 0.9677 - val_loss: 0.0609 - val_accuracy: 0.8666\n",
      "Epoch 56/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0121 - accuracy: 0.9718 - val_loss: 0.0619 - val_accuracy: 0.8666\n",
      "Epoch 57/2000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.0119 - accuracy: 0.9694 - val_loss: 0.0625 - val_accuracy: 0.8666\n",
      "Epoch 58/2000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.0168 - accuracy: 0.9571 - val_loss: 0.0632 - val_accuracy: 0.8666\n",
      "Epoch 59/2000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.0104 - accuracy: 0.9748 - val_loss: 0.0638 - val_accuracy: 0.8666\n",
      "Epoch 60/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0121 - accuracy: 0.9726 - val_loss: 0.0649 - val_accuracy: 0.8666\n",
      "Epoch 61/2000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0125 - accuracy: 0.9702 - val_loss: 0.0655 - val_accuracy: 0.8666\n",
      "Epoch 62/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0134 - accuracy: 0.9699 - val_loss: 0.0659 - val_accuracy: 0.8666\n",
      "Epoch 63/2000\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0091 - accuracy: 0.9792 - val_loss: 0.0662 - val_accuracy: 0.8666\n",
      "Epoch 64/2000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.0132 - accuracy: 0.9684 - val_loss: 0.0663 - val_accuracy: 0.8666\n",
      "Epoch 65/2000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.0122 - accuracy: 0.9714 - val_loss: 0.0664 - val_accuracy: 0.8666\n",
      "Epoch 66/2000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0075 - accuracy: 0.9820 - val_loss: 0.0665 - val_accuracy: 0.8666\n",
      "Epoch 67/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0091 - accuracy: 0.9771 - val_loss: 0.0665 - val_accuracy: 0.8666\n",
      "Epoch 68/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0131 - accuracy: 0.9657 - val_loss: 0.0664 - val_accuracy: 0.8666\n",
      "Epoch 69/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0086 - accuracy: 0.9804 - val_loss: 0.0662 - val_accuracy: 0.8666\n",
      "Epoch 70/2000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0095 - accuracy: 0.9774 - val_loss: 0.0662 - val_accuracy: 0.8666\n",
      "Epoch 71/2000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0093 - accuracy: 0.9783 - val_loss: 0.0664 - val_accuracy: 0.8666\n",
      "Epoch 72/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0080 - accuracy: 0.9826 - val_loss: 0.0666 - val_accuracy: 0.8666\n",
      "Epoch 73/2000\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0087 - accuracy: 0.9793 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 74/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0086 - accuracy: 0.9793 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 75/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0108 - accuracy: 0.9745 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 76/2000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.0123 - accuracy: 0.9712 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 77/2000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.0099 - accuracy: 0.9759 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 78/2000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0167 - accuracy: 0.9577 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 79/2000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0070 - accuracy: 0.9833 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 80/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0106 - accuracy: 0.9757 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 81/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0139 - accuracy: 0.9649 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 82/2000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.0096 - accuracy: 0.9780 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 83/2000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.0094 - accuracy: 0.9790 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 84/2000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0087 - accuracy: 0.9801 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 85/2000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0070 - accuracy: 0.9833 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 86/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0096 - accuracy: 0.9761 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 87/2000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.0109 - accuracy: 0.9756 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 88/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0082 - accuracy: 0.9791 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 89/2000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0073 - accuracy: 0.9817 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 90/2000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.0068 - accuracy: 0.9823 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 91/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0087 - accuracy: 0.9785 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 92/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0089 - accuracy: 0.9792 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 93/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0078 - accuracy: 0.9812 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 94/2000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0093 - accuracy: 0.9784 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 95/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0074 - accuracy: 0.9818 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 96/2000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.0085 - accuracy: 0.9791 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 97/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0077 - accuracy: 0.9827 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 98/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0097 - accuracy: 0.9761 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 99/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0111 - accuracy: 0.9718 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 100/2000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0088 - accuracy: 0.9779 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 101/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0089 - accuracy: 0.9781 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 102/2000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.0122 - accuracy: 0.9722 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 103/2000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.0088 - accuracy: 0.9793 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 104/2000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0080 - accuracy: 0.9812 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 105/2000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.0101 - accuracy: 0.9763 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 106/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0081 - accuracy: 0.9816 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 107/2000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0106 - accuracy: 0.9742 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 108/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0091 - accuracy: 0.9774 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 109/2000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.0066 - accuracy: 0.9836 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 110/2000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.0074 - accuracy: 0.9811 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 111/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0127 - accuracy: 0.9687 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 112/2000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0058 - accuracy: 0.9862 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 113/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0072 - accuracy: 0.9828 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 114/2000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.0082 - accuracy: 0.9803 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 115/2000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.0086 - accuracy: 0.9800 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 116/2000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.0095 - accuracy: 0.9781 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 117/2000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.0080 - accuracy: 0.9813 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 118/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0078 - accuracy: 0.9821 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 119/2000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0078 - accuracy: 0.9824 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 120/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0071 - accuracy: 0.9838 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 121/2000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0103 - accuracy: 0.9744 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 122/2000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.0097 - accuracy: 0.9760 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 123/2000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.0062 - accuracy: 0.9847 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 124/2000\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0067 - accuracy: 0.9835 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 125/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0052 - accuracy: 0.9878 - val_loss: 0.0665 - val_accuracy: 0.8666\n",
      "Epoch 126/2000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.0084 - accuracy: 0.9802 - val_loss: 0.0663 - val_accuracy: 0.8667\n",
      "Epoch 127/2000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.0057 - accuracy: 0.9862 - val_loss: 0.0662 - val_accuracy: 0.8667\n",
      "Epoch 128/2000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.0082 - accuracy: 0.9800 - val_loss: 0.0664 - val_accuracy: 0.8666\n",
      "Epoch 129/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0062 - accuracy: 0.9860 - val_loss: 0.0666 - val_accuracy: 0.8666\n",
      "Epoch 130/2000\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0055 - accuracy: 0.9864 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 131/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0112 - accuracy: 0.9704 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 132/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0065 - accuracy: 0.9836 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 133/2000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0083 - accuracy: 0.9804 - val_loss: 0.0666 - val_accuracy: 0.8666\n",
      "Epoch 134/2000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.0067 - accuracy: 0.9838 - val_loss: 0.0666 - val_accuracy: 0.8666\n",
      "Epoch 135/2000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.0100 - accuracy: 0.9772 - val_loss: 0.0666 - val_accuracy: 0.8666\n",
      "Epoch 136/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0073 - accuracy: 0.9832 - val_loss: 0.0666 - val_accuracy: 0.8666\n",
      "Epoch 137/2000\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0085 - accuracy: 0.9794 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 138/2000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0070 - accuracy: 0.9829 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 139/2000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.0084 - accuracy: 0.9802 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 140/2000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0076 - accuracy: 0.9820 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 141/2000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.0056 - accuracy: 0.9864 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 142/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0060 - accuracy: 0.9864 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 143/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0067 - accuracy: 0.9835 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 144/2000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0068 - accuracy: 0.9845 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 145/2000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0082 - accuracy: 0.9804 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 146/2000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.0058 - accuracy: 0.9869 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 147/2000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.0064 - accuracy: 0.9841 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 148/2000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0067 - accuracy: 0.9841 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 149/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0088 - accuracy: 0.9775 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 150/2000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.0065 - accuracy: 0.9848 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 151/2000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.0100 - accuracy: 0.9748 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 152/2000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0118 - accuracy: 0.9734 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 153/2000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.0063 - accuracy: 0.9843 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 154/2000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0055 - accuracy: 0.9870 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 155/2000\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0075 - accuracy: 0.9827 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 156/2000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0074 - accuracy: 0.9826 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 157/2000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0050 - accuracy: 0.9882 - val_loss: 0.0667 - val_accuracy: 0.8666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/2000\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0075 - accuracy: 0.9805 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 159/2000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.0078 - accuracy: 0.9811 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 160/2000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0078 - accuracy: 0.9811 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 161/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0064 - accuracy: 0.9851 - val_loss: 0.0666 - val_accuracy: 0.8666\n",
      "Epoch 162/2000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0062 - accuracy: 0.9854 - val_loss: 0.0664 - val_accuracy: 0.8666\n",
      "Epoch 163/2000\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0068 - accuracy: 0.9851 - val_loss: 0.0664 - val_accuracy: 0.8666\n",
      "Epoch 164/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0057 - accuracy: 0.9861 - val_loss: 0.0663 - val_accuracy: 0.8666\n",
      "Epoch 165/2000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0068 - accuracy: 0.9835 - val_loss: 0.0664 - val_accuracy: 0.8666\n",
      "Epoch 166/2000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.0057 - accuracy: 0.9865 - val_loss: 0.0666 - val_accuracy: 0.8666\n",
      "Epoch 167/2000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.0084 - accuracy: 0.9778 - val_loss: 0.0666 - val_accuracy: 0.8666\n",
      "Epoch 168/2000\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0081 - accuracy: 0.9797 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 169/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0070 - accuracy: 0.9827 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 170/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0055 - accuracy: 0.9875 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 171/2000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0076 - accuracy: 0.9819 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 172/2000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0060 - accuracy: 0.9865 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 173/2000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0060 - accuracy: 0.9859 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 174/2000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.0068 - accuracy: 0.9835 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 175/2000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0050 - accuracy: 0.9882 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 176/2000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0077 - accuracy: 0.9816 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 177/2000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0064 - accuracy: 0.9849 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 178/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0079 - accuracy: 0.9799 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 179/2000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.0089 - accuracy: 0.9771 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 180/2000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.0063 - accuracy: 0.9852 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 181/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0060 - accuracy: 0.9857 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 182/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0061 - accuracy: 0.9860 - val_loss: 0.0667 - val_accuracy: 0.8666\n",
      "Epoch 183/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0065 - accuracy: 0.9855 - val_loss: 0.0666 - val_accuracy: 0.8666\n",
      "Epoch 184/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0080 - accuracy: 0.9816 - val_loss: 0.0666 - val_accuracy: 0.8666\n",
      "Epoch 185/2000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.0063 - accuracy: 0.9854 - val_loss: 0.0665 - val_accuracy: 0.8666\n",
      "Epoch 186/2000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.0060 - accuracy: 0.9846 - val_loss: 0.0662 - val_accuracy: 0.8667\n",
      "Epoch 187/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0047 - accuracy: 0.9886 - val_loss: 0.0660 - val_accuracy: 0.8668\n",
      "Epoch 188/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0060 - accuracy: 0.9848 - val_loss: 0.0655 - val_accuracy: 0.8672\n",
      "Epoch 189/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0052 - accuracy: 0.9873 - val_loss: 0.0652 - val_accuracy: 0.8676\n",
      "Epoch 190/2000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0082 - accuracy: 0.9789 - val_loss: 0.0653 - val_accuracy: 0.8675\n",
      "Epoch 191/2000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.0066 - accuracy: 0.9829 - val_loss: 0.0651 - val_accuracy: 0.8678\n",
      "Epoch 192/2000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0059 - accuracy: 0.9857 - val_loss: 0.0655 - val_accuracy: 0.8673\n",
      "Epoch 193/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0062 - accuracy: 0.9852 - val_loss: 0.0660 - val_accuracy: 0.8668\n",
      "Epoch 194/2000\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0050 - accuracy: 0.9883 - val_loss: 0.0665 - val_accuracy: 0.8665\n",
      "Epoch 195/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0068 - accuracy: 0.9836 - val_loss: 0.0667 - val_accuracy: 0.8664\n",
      "Epoch 196/2000\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0065 - accuracy: 0.9850 - val_loss: 0.0668 - val_accuracy: 0.8664\n",
      "Epoch 197/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0087 - accuracy: 0.9799 - val_loss: 0.0668 - val_accuracy: 0.8665\n",
      "Epoch 198/2000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.0053 - accuracy: 0.9874 - val_loss: 0.0668 - val_accuracy: 0.8666\n",
      "Epoch 199/2000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.0053 - accuracy: 0.9880 - val_loss: 0.0668 - val_accuracy: 0.8666\n",
      "Epoch 200/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0074 - accuracy: 0.9817 - val_loss: 0.0668 - val_accuracy: 0.8665\n",
      "Epoch 201/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0057 - accuracy: 0.9859 - val_loss: 0.0668 - val_accuracy: 0.8665\n",
      "Epoch 202/2000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0060 - accuracy: 0.9854 - val_loss: 0.0668 - val_accuracy: 0.8665\n",
      "Epoch 203/2000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.0063 - accuracy: 0.9837 - val_loss: 0.0669 - val_accuracy: 0.8661\n",
      "Epoch 204/2000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.0054 - accuracy: 0.9871 - val_loss: 0.0666 - val_accuracy: 0.8650\n",
      "Epoch 205/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0074 - accuracy: 0.9815 - val_loss: 0.0652 - val_accuracy: 0.8634\n",
      "Epoch 206/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0055 - accuracy: 0.9864 - val_loss: 0.0646 - val_accuracy: 0.8590\n",
      "Epoch 207/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0057 - accuracy: 0.9866 - val_loss: 0.0675 - val_accuracy: 0.8479\n",
      "Epoch 208/2000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0062 - accuracy: 0.9854 - val_loss: 0.0740 - val_accuracy: 0.8309\n",
      "Epoch 209/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0061 - accuracy: 0.9863 - val_loss: 0.0808 - val_accuracy: 0.8145\n",
      "Epoch 210/2000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0053 - accuracy: 0.9872 - val_loss: 0.0869 - val_accuracy: 0.8005\n",
      "Epoch 211/2000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0048 - accuracy: 0.9895 - val_loss: 0.0922 - val_accuracy: 0.7886\n",
      "Epoch 212/2000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.0051 - accuracy: 0.9880 - val_loss: 0.0941 - val_accuracy: 0.7842\n",
      "Epoch 213/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0062 - accuracy: 0.9849 - val_loss: 0.0906 - val_accuracy: 0.7916\n",
      "Epoch 214/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0056 - accuracy: 0.9861 - val_loss: 0.0876 - val_accuracy: 0.7983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/2000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.0055 - accuracy: 0.9869 - val_loss: 0.0845 - val_accuracy: 0.8053\n",
      "Epoch 216/2000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.0066 - accuracy: 0.9839 - val_loss: 0.0800 - val_accuracy: 0.8160\n",
      "Epoch 217/2000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0057 - accuracy: 0.9861 - val_loss: 0.0763 - val_accuracy: 0.8250\n",
      "Epoch 218/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0066 - accuracy: 0.9833 - val_loss: 0.0745 - val_accuracy: 0.8297\n",
      "Epoch 219/2000\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0050 - accuracy: 0.9880 - val_loss: 0.0748 - val_accuracy: 0.8292\n",
      "Epoch 220/2000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0050 - accuracy: 0.9887 - val_loss: 0.0710 - val_accuracy: 0.8389\n",
      "Epoch 221/2000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.0061 - accuracy: 0.9851 - val_loss: 0.0678 - val_accuracy: 0.8476\n",
      "Epoch 222/2000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.0062 - accuracy: 0.9843 - val_loss: 0.0656 - val_accuracy: 0.8537\n",
      "Epoch 223/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0055 - accuracy: 0.9869 - val_loss: 0.0649 - val_accuracy: 0.8560\n",
      "Epoch 224/2000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0059 - accuracy: 0.9864 - val_loss: 0.0636 - val_accuracy: 0.8603\n",
      "Epoch 225/2000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.0062 - accuracy: 0.9846 - val_loss: 0.0628 - val_accuracy: 0.8629\n",
      "Epoch 226/2000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0070 - accuracy: 0.9831 - val_loss: 0.0620 - val_accuracy: 0.8651\n",
      "Epoch 227/2000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.0046 - accuracy: 0.9894 - val_loss: 0.0613 - val_accuracy: 0.8668\n",
      "Epoch 228/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0062 - accuracy: 0.9844 - val_loss: 0.0607 - val_accuracy: 0.8690\n",
      "Epoch 229/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0056 - accuracy: 0.9866 - val_loss: 0.0605 - val_accuracy: 0.8703\n",
      "Epoch 230/2000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0048 - accuracy: 0.9888 - val_loss: 0.0612 - val_accuracy: 0.8710\n",
      "Epoch 231/2000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.0044 - accuracy: 0.9897 - val_loss: 0.0621 - val_accuracy: 0.8706\n",
      "Epoch 232/2000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.0052 - accuracy: 0.9874 - val_loss: 0.0631 - val_accuracy: 0.8699\n",
      "Epoch 233/2000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.0043 - accuracy: 0.9903 - val_loss: 0.0641 - val_accuracy: 0.8690\n",
      "Epoch 234/2000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0042 - accuracy: 0.9897 - val_loss: 0.0649 - val_accuracy: 0.8682\n",
      "Epoch 235/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0051 - accuracy: 0.9874 - val_loss: 0.0654 - val_accuracy: 0.8676\n",
      "Epoch 236/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0053 - accuracy: 0.9869 - val_loss: 0.0657 - val_accuracy: 0.8674\n",
      "Epoch 237/2000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.0052 - accuracy: 0.9876 - val_loss: 0.0658 - val_accuracy: 0.8672\n",
      "Epoch 238/2000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.0036 - accuracy: 0.9912 - val_loss: 0.0659 - val_accuracy: 0.8671\n",
      "Epoch 239/2000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.0063 - accuracy: 0.9846 - val_loss: 0.0661 - val_accuracy: 0.8670\n",
      "Epoch 240/2000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0059 - accuracy: 0.9858 - val_loss: 0.0661 - val_accuracy: 0.8669\n",
      "Epoch 241/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0043 - accuracy: 0.9897 - val_loss: 0.0662 - val_accuracy: 0.8668\n",
      "Epoch 242/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0046 - accuracy: 0.9891 - val_loss: 0.0663 - val_accuracy: 0.8668\n",
      "Epoch 243/2000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0047 - accuracy: 0.9888 - val_loss: 0.0664 - val_accuracy: 0.8667\n",
      "Epoch 244/2000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.0054 - accuracy: 0.9879 - val_loss: 0.0664 - val_accuracy: 0.8667\n",
      "Epoch 245/2000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0060 - accuracy: 0.9853 - val_loss: 0.0665 - val_accuracy: 0.8666\n",
      "Epoch 246/2000\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0060 - accuracy: 0.9859 - val_loss: 0.0665 - val_accuracy: 0.8666\n",
      "Epoch 247/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0047 - accuracy: 0.9895 - val_loss: 0.0665 - val_accuracy: 0.8666\n",
      "Epoch 248/2000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0041 - accuracy: 0.9902 - val_loss: 0.0665 - val_accuracy: 0.8666\n",
      "Epoch 249/2000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.0054 - accuracy: 0.9866 - val_loss: 0.0665 - val_accuracy: 0.8666\n",
      "Epoch 250/2000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0060 - accuracy: 0.9845 - val_loss: 0.0664 - val_accuracy: 0.8667\n",
      "Epoch 251/2000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0075 - accuracy: 0.9808 - val_loss: 0.0659 - val_accuracy: 0.8670\n",
      "Epoch 252/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0068 - accuracy: 0.9831 - val_loss: 0.0646 - val_accuracy: 0.8680\n",
      "Epoch 253/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0065 - accuracy: 0.9854 - val_loss: 0.0633 - val_accuracy: 0.8691\n",
      "Epoch 254/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0061 - accuracy: 0.9861 - val_loss: 0.0619 - val_accuracy: 0.8707\n",
      "Epoch 255/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0043 - accuracy: 0.9897 - val_loss: 0.0611 - val_accuracy: 0.8715\n",
      "Epoch 256/2000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.0059 - accuracy: 0.9867 - val_loss: 0.0615 - val_accuracy: 0.8710\n",
      "Epoch 257/2000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0038 - accuracy: 0.9912 - val_loss: 0.0621 - val_accuracy: 0.8705\n",
      "Epoch 258/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0052 - accuracy: 0.9871 - val_loss: 0.0631 - val_accuracy: 0.8695\n",
      "Epoch 259/2000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0060 - accuracy: 0.9846 - val_loss: 0.0638 - val_accuracy: 0.8690\n",
      "Epoch 260/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0051 - accuracy: 0.9869 - val_loss: 0.0643 - val_accuracy: 0.8685\n",
      "Epoch 261/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0061 - accuracy: 0.9852 - val_loss: 0.0648 - val_accuracy: 0.8681\n",
      "Epoch 262/2000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.0048 - accuracy: 0.9888 - val_loss: 0.0651 - val_accuracy: 0.8679\n",
      "Epoch 263/2000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0054 - accuracy: 0.9876 - val_loss: 0.0653 - val_accuracy: 0.8677\n",
      "Epoch 264/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0089 - accuracy: 0.9776 - val_loss: 0.0649 - val_accuracy: 0.8682\n",
      "Epoch 265/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0060 - accuracy: 0.9859 - val_loss: 0.0626 - val_accuracy: 0.8706\n",
      "Epoch 266/2000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0056 - accuracy: 0.9876 - val_loss: 0.0599 - val_accuracy: 0.8725\n",
      "Epoch 267/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0053 - accuracy: 0.9876 - val_loss: 0.0614 - val_accuracy: 0.8651\n",
      "Epoch 268/2000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0054 - accuracy: 0.9879 - val_loss: 0.0666 - val_accuracy: 0.8511\n",
      "Epoch 269/2000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0079 - accuracy: 0.9799 - val_loss: 0.0719 - val_accuracy: 0.8383\n",
      "Epoch 270/2000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.0050 - accuracy: 0.9886 - val_loss: 0.0783 - val_accuracy: 0.8230\n",
      "Epoch 271/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0074 - accuracy: 0.9817 - val_loss: 0.0827 - val_accuracy: 0.8126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/2000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0049 - accuracy: 0.9877 - val_loss: 0.0857 - val_accuracy: 0.8054\n",
      "Epoch 273/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0040 - accuracy: 0.9907 - val_loss: 0.0887 - val_accuracy: 0.7985\n",
      "Epoch 274/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0046 - accuracy: 0.9888 - val_loss: 0.0921 - val_accuracy: 0.7906\n",
      "Epoch 275/2000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0046 - accuracy: 0.9893 - val_loss: 0.0888 - val_accuracy: 0.7976\n",
      "Epoch 276/2000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0046 - accuracy: 0.9896 - val_loss: 0.0843 - val_accuracy: 0.8075\n",
      "Epoch 277/2000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0049 - accuracy: 0.9881 - val_loss: 0.0761 - val_accuracy: 0.8258\n",
      "Epoch 278/2000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0054 - accuracy: 0.9872 - val_loss: 0.0697 - val_accuracy: 0.8406\n",
      "Epoch 279/2000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0044 - accuracy: 0.9886 - val_loss: 0.0656 - val_accuracy: 0.8508\n",
      "Epoch 280/2000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.0044 - accuracy: 0.9893 - val_loss: 0.0622 - val_accuracy: 0.8596\n",
      "Epoch 281/2000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.0056 - accuracy: 0.9863 - val_loss: 0.0598 - val_accuracy: 0.8667\n",
      "Epoch 282/2000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.0057 - accuracy: 0.9858 - val_loss: 0.0586 - val_accuracy: 0.8708\n",
      "Epoch 283/2000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.0041 - accuracy: 0.9901 - val_loss: 0.0586 - val_accuracy: 0.8725\n",
      "Epoch 284/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0048 - accuracy: 0.9886 - val_loss: 0.0592 - val_accuracy: 0.8727\n",
      "Epoch 285/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0053 - accuracy: 0.9876 - val_loss: 0.0606 - val_accuracy: 0.8717\n",
      "Epoch 286/2000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.0056 - accuracy: 0.9870 - val_loss: 0.0623 - val_accuracy: 0.8698\n",
      "Epoch 287/2000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0048 - accuracy: 0.9889 - val_loss: 0.0641 - val_accuracy: 0.8681\n",
      "Epoch 288/2000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0056 - accuracy: 0.9857 - val_loss: 0.0651 - val_accuracy: 0.8673\n",
      "Epoch 289/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0077 - accuracy: 0.9806 - val_loss: 0.0658 - val_accuracy: 0.8668\n",
      "Epoch 290/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0055 - accuracy: 0.9857 - val_loss: 0.0660 - val_accuracy: 0.8667\n",
      "Epoch 291/2000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.0042 - accuracy: 0.9903 - val_loss: 0.0662 - val_accuracy: 0.8666\n",
      "Epoch 292/2000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.0058 - accuracy: 0.9850 - val_loss: 0.0662 - val_accuracy: 0.8666\n",
      "Epoch 293/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0052 - accuracy: 0.9883 - val_loss: 0.0661 - val_accuracy: 0.8667\n",
      "Epoch 294/2000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0041 - accuracy: 0.9910 - val_loss: 0.0660 - val_accuracy: 0.8667\n",
      "Epoch 295/2000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.0045 - accuracy: 0.9899 - val_loss: 0.0658 - val_accuracy: 0.8668\n",
      "Epoch 296/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0048 - accuracy: 0.9885 - val_loss: 0.0656 - val_accuracy: 0.8670\n",
      "Epoch 297/2000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0038 - accuracy: 0.9909 - val_loss: 0.0654 - val_accuracy: 0.8673\n",
      "Epoch 298/2000\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0046 - accuracy: 0.9888 - val_loss: 0.0652 - val_accuracy: 0.8676\n",
      "Epoch 299/2000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0041 - accuracy: 0.9896 - val_loss: 0.0649 - val_accuracy: 0.8681\n",
      "Epoch 300/2000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.0075 - accuracy: 0.9808 - val_loss: 0.0640 - val_accuracy: 0.8693\n",
      "Epoch 301/2000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.0035 - accuracy: 0.9922 - val_loss: 0.0630 - val_accuracy: 0.8708\n",
      "Epoch 302/2000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.0047 - accuracy: 0.9884 - val_loss: 0.0615 - val_accuracy: 0.8729\n",
      "Epoch 303/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0053 - accuracy: 0.9866 - val_loss: 0.0594 - val_accuracy: 0.8758\n",
      "Epoch 304/2000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.0082 - accuracy: 0.9786 - val_loss: 0.0565 - val_accuracy: 0.8800\n",
      "Epoch 305/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0046 - accuracy: 0.9893 - val_loss: 0.0543 - val_accuracy: 0.8833\n",
      "Epoch 306/2000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.0050 - accuracy: 0.9882 - val_loss: 0.0527 - val_accuracy: 0.8853\n",
      "Epoch 307/2000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.0052 - accuracy: 0.9876 - val_loss: 0.0521 - val_accuracy: 0.8852\n",
      "Epoch 308/2000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.0051 - accuracy: 0.9881 - val_loss: 0.0524 - val_accuracy: 0.8838\n",
      "Epoch 309/2000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0056 - accuracy: 0.9859 - val_loss: 0.0531 - val_accuracy: 0.8815\n",
      "Epoch 310/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0047 - accuracy: 0.9894 - val_loss: 0.0565 - val_accuracy: 0.8754\n",
      "Epoch 311/2000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0048 - accuracy: 0.9887 - val_loss: 0.0596 - val_accuracy: 0.8705\n",
      "Epoch 312/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0049 - accuracy: 0.9887 - val_loss: 0.0624 - val_accuracy: 0.8671\n",
      "Epoch 313/2000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.0063 - accuracy: 0.9846 - val_loss: 0.0640 - val_accuracy: 0.8661\n",
      "Epoch 314/2000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.0039 - accuracy: 0.9906 - val_loss: 0.0651 - val_accuracy: 0.8657\n",
      "Epoch 315/2000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0071 - accuracy: 0.9817 - val_loss: 0.0650 - val_accuracy: 0.8661\n",
      "Epoch 316/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0048 - accuracy: 0.9885 - val_loss: 0.0647 - val_accuracy: 0.8671\n",
      "Epoch 317/2000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0046 - accuracy: 0.9890 - val_loss: 0.0648 - val_accuracy: 0.8676\n",
      "Epoch 318/2000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0041 - accuracy: 0.9902 - val_loss: 0.0649 - val_accuracy: 0.8679\n",
      "Epoch 319/2000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.0049 - accuracy: 0.9887 - val_loss: 0.0650 - val_accuracy: 0.8681\n",
      "Epoch 320/2000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.0049 - accuracy: 0.9880 - val_loss: 0.0652 - val_accuracy: 0.8680\n",
      "Epoch 321/2000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0044 - accuracy: 0.9887 - val_loss: 0.0652 - val_accuracy: 0.8681\n",
      "Epoch 322/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0039 - accuracy: 0.9904 - val_loss: 0.0651 - val_accuracy: 0.8683\n",
      "Epoch 323/2000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0052 - accuracy: 0.9870 - val_loss: 0.0649 - val_accuracy: 0.8686\n",
      "Epoch 324/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0041 - accuracy: 0.9906 - val_loss: 0.0645 - val_accuracy: 0.8691\n",
      "Epoch 325/2000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.0045 - accuracy: 0.9900 - val_loss: 0.0641 - val_accuracy: 0.8698\n",
      "Epoch 326/2000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.0037 - accuracy: 0.9909 - val_loss: 0.0636 - val_accuracy: 0.8705\n",
      "Epoch 327/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0045 - accuracy: 0.9888 - val_loss: 0.0632 - val_accuracy: 0.8712\n",
      "Epoch 328/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0057 - accuracy: 0.9856 - val_loss: 0.0625 - val_accuracy: 0.8722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/2000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0057 - accuracy: 0.9852 - val_loss: 0.0613 - val_accuracy: 0.8738\n",
      "Epoch 330/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0039 - accuracy: 0.9904 - val_loss: 0.0600 - val_accuracy: 0.8754\n",
      "Epoch 331/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0043 - accuracy: 0.9900 - val_loss: 0.0588 - val_accuracy: 0.8770\n",
      "Epoch 332/2000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.0059 - accuracy: 0.9860 - val_loss: 0.0582 - val_accuracy: 0.8777\n",
      "Epoch 333/2000\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0052 - accuracy: 0.9875 - val_loss: 0.0580 - val_accuracy: 0.8778\n",
      "Epoch 334/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0055 - accuracy: 0.9872 - val_loss: 0.0582 - val_accuracy: 0.8776\n",
      "Epoch 335/2000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0041 - accuracy: 0.9902 - val_loss: 0.0587 - val_accuracy: 0.8768\n",
      "Epoch 336/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0047 - accuracy: 0.9894 - val_loss: 0.0602 - val_accuracy: 0.8747\n",
      "Epoch 337/2000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.0047 - accuracy: 0.9887 - val_loss: 0.0614 - val_accuracy: 0.8730\n",
      "Epoch 338/2000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.0044 - accuracy: 0.9882 - val_loss: 0.0620 - val_accuracy: 0.8722\n",
      "Epoch 339/2000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.0048 - accuracy: 0.9883 - val_loss: 0.0621 - val_accuracy: 0.8719\n",
      "Epoch 340/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0087 - accuracy: 0.9770 - val_loss: 0.0610 - val_accuracy: 0.8729\n",
      "Epoch 341/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0040 - accuracy: 0.9906 - val_loss: 0.0601 - val_accuracy: 0.8737\n",
      "Epoch 342/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0048 - accuracy: 0.9880 - val_loss: 0.0591 - val_accuracy: 0.8744\n",
      "Epoch 343/2000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.0043 - accuracy: 0.9896 - val_loss: 0.0584 - val_accuracy: 0.8745\n",
      "Epoch 344/2000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.0053 - accuracy: 0.9877 - val_loss: 0.0584 - val_accuracy: 0.8740\n",
      "Epoch 345/2000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.0042 - accuracy: 0.9900 - val_loss: 0.0578 - val_accuracy: 0.8748\n",
      "Epoch 346/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0045 - accuracy: 0.9897 - val_loss: 0.0576 - val_accuracy: 0.8752\n",
      "Epoch 347/2000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0045 - accuracy: 0.9893 - val_loss: 0.0577 - val_accuracy: 0.8754\n",
      "Epoch 348/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0054 - accuracy: 0.9871 - val_loss: 0.0582 - val_accuracy: 0.8756\n",
      "Epoch 349/2000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0059 - accuracy: 0.9861 - val_loss: 0.0594 - val_accuracy: 0.8749\n",
      "Epoch 350/2000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.0063 - accuracy: 0.9835 - val_loss: 0.0600 - val_accuracy: 0.8747\n",
      "Epoch 351/2000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.0041 - accuracy: 0.9906 - val_loss: 0.0612 - val_accuracy: 0.8735\n",
      "Epoch 352/2000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0034 - accuracy: 0.9918 - val_loss: 0.0623 - val_accuracy: 0.8721\n",
      "Epoch 353/2000\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0038 - accuracy: 0.9909 - val_loss: 0.0631 - val_accuracy: 0.8710\n",
      "Epoch 354/2000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0042 - accuracy: 0.9898 - val_loss: 0.0637 - val_accuracy: 0.8702\n",
      "Epoch 355/2000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.0071 - accuracy: 0.9821 - val_loss: 0.0639 - val_accuracy: 0.8698\n",
      "Epoch 356/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0046 - accuracy: 0.9886 - val_loss: 0.0639 - val_accuracy: 0.8699\n",
      "Epoch 357/2000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.0046 - accuracy: 0.9892 - val_loss: 0.0638 - val_accuracy: 0.8701\n",
      "Epoch 358/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0055 - accuracy: 0.9871 - val_loss: 0.0641 - val_accuracy: 0.8696\n",
      "Epoch 359/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0056 - accuracy: 0.9867 - val_loss: 0.0645 - val_accuracy: 0.8691\n",
      "Epoch 360/2000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0060 - accuracy: 0.9868 - val_loss: 0.0651 - val_accuracy: 0.8684\n",
      "Epoch 361/2000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.0048 - accuracy: 0.9890 - val_loss: 0.0656 - val_accuracy: 0.8677\n",
      "Epoch 362/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0046 - accuracy: 0.9885 - val_loss: 0.0659 - val_accuracy: 0.8673\n",
      "Epoch 363/2000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.0043 - accuracy: 0.9898 - val_loss: 0.0661 - val_accuracy: 0.8671\n",
      "Epoch 364/2000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.0031 - accuracy: 0.9930 - val_loss: 0.0662 - val_accuracy: 0.8669\n",
      "Epoch 365/2000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0041 - accuracy: 0.9895 - val_loss: 0.0663 - val_accuracy: 0.8669\n",
      "Epoch 366/2000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.0063 - accuracy: 0.9841 - val_loss: 0.0657 - val_accuracy: 0.8675\n",
      "Epoch 367/2000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0042 - accuracy: 0.9897 - val_loss: 0.0647 - val_accuracy: 0.8687\n",
      "Epoch 368/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0055 - accuracy: 0.9862 - val_loss: 0.0617 - val_accuracy: 0.8727\n",
      "Epoch 369/2000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0047 - accuracy: 0.9883 - val_loss: 0.0573 - val_accuracy: 0.8790\n",
      "Epoch 370/2000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.0031 - accuracy: 0.9929 - val_loss: 0.0538 - val_accuracy: 0.8835\n",
      "Epoch 371/2000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.0035 - accuracy: 0.9914 - val_loss: 0.0536 - val_accuracy: 0.8814\n",
      "Epoch 372/2000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.0048 - accuracy: 0.9891 - val_loss: 0.0577 - val_accuracy: 0.8712\n",
      "Epoch 373/2000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0054 - accuracy: 0.9872 - val_loss: 0.0653 - val_accuracy: 0.8539\n",
      "Epoch 374/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0040 - accuracy: 0.9904 - val_loss: 0.0751 - val_accuracy: 0.8323\n",
      "Epoch 375/2000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0038 - accuracy: 0.9908 - val_loss: 0.0868 - val_accuracy: 0.8071\n",
      "Epoch 376/2000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.0037 - accuracy: 0.9909 - val_loss: 0.0972 - val_accuracy: 0.7847\n",
      "Epoch 377/2000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.0037 - accuracy: 0.9916 - val_loss: 0.1047 - val_accuracy: 0.7685\n",
      "Epoch 378/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0047 - accuracy: 0.9887 - val_loss: 0.1091 - val_accuracy: 0.7589\n",
      "Epoch 379/2000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0058 - accuracy: 0.9858 - val_loss: 0.0982 - val_accuracy: 0.7815\n",
      "Epoch 380/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0060 - accuracy: 0.9849 - val_loss: 0.0902 - val_accuracy: 0.7987\n",
      "Epoch 381/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0050 - accuracy: 0.9882 - val_loss: 0.0828 - val_accuracy: 0.8147\n",
      "Epoch 382/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0055 - accuracy: 0.9858 - val_loss: 0.0758 - val_accuracy: 0.8298\n",
      "Epoch 383/2000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.0039 - accuracy: 0.9905 - val_loss: 0.0697 - val_accuracy: 0.8435\n",
      "Epoch 384/2000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.0042 - accuracy: 0.9898 - val_loss: 0.0650 - val_accuracy: 0.8538\n",
      "Epoch 385/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0051 - accuracy: 0.9882 - val_loss: 0.0590 - val_accuracy: 0.8673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/2000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0046 - accuracy: 0.9888 - val_loss: 0.0564 - val_accuracy: 0.8737\n",
      "Epoch 387/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0037 - accuracy: 0.9911 - val_loss: 0.0553 - val_accuracy: 0.8768\n",
      "Epoch 388/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0046 - accuracy: 0.9896 - val_loss: 0.0545 - val_accuracy: 0.8792\n",
      "Epoch 389/2000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.0053 - accuracy: 0.9871 - val_loss: 0.0545 - val_accuracy: 0.8800\n",
      "Epoch 390/2000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.0028 - accuracy: 0.9933 - val_loss: 0.0549 - val_accuracy: 0.8802\n",
      "Epoch 391/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0034 - accuracy: 0.9921 - val_loss: 0.0551 - val_accuracy: 0.8804\n",
      "Epoch 392/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0053 - accuracy: 0.9870 - val_loss: 0.0550 - val_accuracy: 0.8813\n",
      "Epoch 393/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0071 - accuracy: 0.9814 - val_loss: 0.0540 - val_accuracy: 0.8825\n",
      "Epoch 394/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0035 - accuracy: 0.9915 - val_loss: 0.0530 - val_accuracy: 0.8836\n",
      "Epoch 395/2000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.0039 - accuracy: 0.9905 - val_loss: 0.0524 - val_accuracy: 0.8842\n",
      "Epoch 396/2000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.0045 - accuracy: 0.9892 - val_loss: 0.0529 - val_accuracy: 0.8824\n",
      "Epoch 397/2000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0037 - accuracy: 0.9914 - val_loss: 0.0538 - val_accuracy: 0.8800\n",
      "Epoch 398/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0055 - accuracy: 0.9876 - val_loss: 0.0532 - val_accuracy: 0.8813\n",
      "Epoch 399/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0039 - accuracy: 0.9907 - val_loss: 0.0527 - val_accuracy: 0.8829\n",
      "Epoch 400/2000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0044 - accuracy: 0.9896 - val_loss: 0.0523 - val_accuracy: 0.8842\n",
      "Epoch 401/2000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.0056 - accuracy: 0.9860 - val_loss: 0.0525 - val_accuracy: 0.8843\n",
      "Epoch 402/2000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.0045 - accuracy: 0.9887 - val_loss: 0.0527 - val_accuracy: 0.8842\n",
      "Epoch 403/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0045 - accuracy: 0.9882 - val_loss: 0.0527 - val_accuracy: 0.8844\n",
      "Epoch 404/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0039 - accuracy: 0.9907 - val_loss: 0.0525 - val_accuracy: 0.8846\n",
      "Epoch 405/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0053 - accuracy: 0.9869 - val_loss: 0.0521 - val_accuracy: 0.8853\n",
      "Epoch 406/2000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0042 - accuracy: 0.9901 - val_loss: 0.0514 - val_accuracy: 0.8870\n",
      "Epoch 407/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0039 - accuracy: 0.9912 - val_loss: 0.0509 - val_accuracy: 0.8881\n",
      "Epoch 408/2000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0034 - accuracy: 0.9918 - val_loss: 0.0510 - val_accuracy: 0.8882\n",
      "Epoch 409/2000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.0045 - accuracy: 0.9891 - val_loss: 0.0512 - val_accuracy: 0.8882\n",
      "Epoch 410/2000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.0045 - accuracy: 0.9887 - val_loss: 0.0515 - val_accuracy: 0.8878\n",
      "Epoch 411/2000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.0039 - accuracy: 0.9902 - val_loss: 0.0516 - val_accuracy: 0.8877\n",
      "Epoch 412/2000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.0048 - accuracy: 0.9881 - val_loss: 0.0515 - val_accuracy: 0.8880\n",
      "Epoch 413/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0030 - accuracy: 0.9933 - val_loss: 0.0517 - val_accuracy: 0.8878\n",
      "Epoch 414/2000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.0036 - accuracy: 0.9917 - val_loss: 0.0520 - val_accuracy: 0.8874\n",
      "Epoch 415/2000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.0033 - accuracy: 0.9925 - val_loss: 0.0519 - val_accuracy: 0.8878\n",
      "Epoch 416/2000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0037 - accuracy: 0.9910 - val_loss: 0.0516 - val_accuracy: 0.8885\n",
      "Epoch 417/2000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.0035 - accuracy: 0.9918 - val_loss: 0.0516 - val_accuracy: 0.8886\n",
      "Epoch 418/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0053 - accuracy: 0.9867 - val_loss: 0.0513 - val_accuracy: 0.8895\n",
      "Epoch 419/2000\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.0039 - accuracy: 0.9906 - val_loss: 0.0511 - val_accuracy: 0.8899\n",
      "Epoch 420/2000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0040 - accuracy: 0.9897 - val_loss: 0.0506 - val_accuracy: 0.8909\n",
      "Epoch 421/2000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.0052 - accuracy: 0.9863 - val_loss: 0.0493 - val_accuracy: 0.8932\n",
      "Epoch 422/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0033 - accuracy: 0.9920 - val_loss: 0.0486 - val_accuracy: 0.8944\n",
      "Epoch 423/2000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.0039 - accuracy: 0.9912 - val_loss: 0.0486 - val_accuracy: 0.8944\n",
      "Epoch 424/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0044 - accuracy: 0.9891 - val_loss: 0.0489 - val_accuracy: 0.8938\n",
      "Epoch 425/2000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0030 - accuracy: 0.9933 - val_loss: 0.0494 - val_accuracy: 0.8927\n",
      "Epoch 426/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0063 - accuracy: 0.9848 - val_loss: 0.0498 - val_accuracy: 0.8920\n",
      "Epoch 427/2000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.0039 - accuracy: 0.9906 - val_loss: 0.0502 - val_accuracy: 0.8913\n",
      "Epoch 428/2000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.0043 - accuracy: 0.9900 - val_loss: 0.0506 - val_accuracy: 0.8907\n",
      "Epoch 429/2000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.0023 - accuracy: 0.9950 - val_loss: 0.0510 - val_accuracy: 0.8901\n",
      "Epoch 430/2000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0040 - accuracy: 0.9900 - val_loss: 0.0512 - val_accuracy: 0.8896\n",
      "Epoch 431/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0043 - accuracy: 0.9901 - val_loss: 0.0515 - val_accuracy: 0.8891\n",
      "Epoch 432/2000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.0037 - accuracy: 0.9911 - val_loss: 0.0517 - val_accuracy: 0.8889\n",
      "Epoch 433/2000\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.0025 - accuracy: 0.9939 - val_loss: 0.0519 - val_accuracy: 0.8887\n",
      "Epoch 434/2000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.0042 - accuracy: 0.9895 - val_loss: 0.0517 - val_accuracy: 0.8892\n",
      "Epoch 435/2000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0047 - accuracy: 0.9881 - val_loss: 0.0509 - val_accuracy: 0.8904\n",
      "Epoch 436/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0035 - accuracy: 0.9914 - val_loss: 0.0502 - val_accuracy: 0.8916\n",
      "Epoch 437/2000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0042 - accuracy: 0.9902 - val_loss: 0.0497 - val_accuracy: 0.8923\n",
      "Epoch 438/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0038 - accuracy: 0.9904 - val_loss: 0.0491 - val_accuracy: 0.8932\n",
      "Epoch 439/2000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.0035 - accuracy: 0.9920 - val_loss: 0.0487 - val_accuracy: 0.8939\n",
      "Epoch 440/2000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.0034 - accuracy: 0.9921 - val_loss: 0.0488 - val_accuracy: 0.8938\n",
      "Epoch 441/2000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0029 - accuracy: 0.9933 - val_loss: 0.0492 - val_accuracy: 0.8931\n",
      "Epoch 442/2000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.0035 - accuracy: 0.9919 - val_loss: 0.0497 - val_accuracy: 0.8921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/2000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0038 - accuracy: 0.9907 - val_loss: 0.0502 - val_accuracy: 0.8912\n",
      "Epoch 444/2000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0045 - accuracy: 0.9887 - val_loss: 0.0505 - val_accuracy: 0.8904\n",
      "Epoch 445/2000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0035 - accuracy: 0.9911 - val_loss: 0.0510 - val_accuracy: 0.8892\n",
      "Epoch 446/2000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.0031 - accuracy: 0.9929 - val_loss: 0.0518 - val_accuracy: 0.8872\n",
      "Epoch 447/2000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.0034 - accuracy: 0.9921 - val_loss: 0.0528 - val_accuracy: 0.8853\n",
      "Epoch 448/2000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0040 - accuracy: 0.9901 - val_loss: 0.0532 - val_accuracy: 0.8846\n",
      "Epoch 449/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0046 - accuracy: 0.9884 - val_loss: 0.0534 - val_accuracy: 0.8842\n",
      "Epoch 450/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0033 - accuracy: 0.9919 - val_loss: 0.0534 - val_accuracy: 0.8842\n",
      "Epoch 451/2000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.0035 - accuracy: 0.9913 - val_loss: 0.0531 - val_accuracy: 0.8848\n",
      "Epoch 452/2000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0049 - accuracy: 0.9875 - val_loss: 0.0528 - val_accuracy: 0.8855\n",
      "Epoch 453/2000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.0034 - accuracy: 0.9922 - val_loss: 0.0526 - val_accuracy: 0.8857\n",
      "Epoch 454/2000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0048 - accuracy: 0.9889 - val_loss: 0.0530 - val_accuracy: 0.8851\n",
      "Epoch 455/2000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.0038 - accuracy: 0.9904 - val_loss: 0.0531 - val_accuracy: 0.8849\n",
      "Epoch 456/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0050 - accuracy: 0.9886 - val_loss: 0.0535 - val_accuracy: 0.8842\n",
      "Epoch 457/2000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.0035 - accuracy: 0.9921 - val_loss: 0.0539 - val_accuracy: 0.8836\n",
      "Epoch 458/2000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0033 - accuracy: 0.9926 - val_loss: 0.0547 - val_accuracy: 0.8825\n",
      "Epoch 459/2000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0042 - accuracy: 0.9900 - val_loss: 0.0550 - val_accuracy: 0.8824\n",
      "Epoch 460/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0038 - accuracy: 0.9904 - val_loss: 0.0548 - val_accuracy: 0.8827\n",
      "Epoch 461/2000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0039 - accuracy: 0.9895 - val_loss: 0.0542 - val_accuracy: 0.8839\n",
      "Epoch 462/2000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0031 - accuracy: 0.9926 - val_loss: 0.0536 - val_accuracy: 0.8850\n",
      "Epoch 463/2000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.0036 - accuracy: 0.9917 - val_loss: 0.0528 - val_accuracy: 0.8866\n",
      "Epoch 464/2000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.0038 - accuracy: 0.9912 - val_loss: 0.0521 - val_accuracy: 0.8880\n",
      "Epoch 465/2000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0034 - accuracy: 0.9922 - val_loss: 0.0516 - val_accuracy: 0.8891\n",
      "Epoch 466/2000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0032 - accuracy: 0.9924 - val_loss: 0.0513 - val_accuracy: 0.8898\n",
      "Epoch 467/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0037 - accuracy: 0.9908 - val_loss: 0.0511 - val_accuracy: 0.8904\n",
      "Epoch 468/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0028 - accuracy: 0.9932 - val_loss: 0.0510 - val_accuracy: 0.8908\n",
      "Epoch 469/2000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0022 - accuracy: 0.9949 - val_loss: 0.0509 - val_accuracy: 0.8910\n",
      "Epoch 470/2000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0039 - accuracy: 0.9904 - val_loss: 0.0507 - val_accuracy: 0.8915\n",
      "Epoch 471/2000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.0030 - accuracy: 0.9922 - val_loss: 0.0504 - val_accuracy: 0.8921\n",
      "Epoch 472/2000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0029 - accuracy: 0.9929 - val_loss: 0.0501 - val_accuracy: 0.8928\n",
      "Epoch 473/2000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0035 - accuracy: 0.9922 - val_loss: 0.0501 - val_accuracy: 0.8930\n",
      "Epoch 474/2000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.0044 - accuracy: 0.9896 - val_loss: 0.0495 - val_accuracy: 0.8941\n",
      "Epoch 475/2000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.0030 - accuracy: 0.9927 - val_loss: 0.0491 - val_accuracy: 0.8949\n",
      "Epoch 476/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0038 - accuracy: 0.9901 - val_loss: 0.0485 - val_accuracy: 0.8959\n",
      "Epoch 477/2000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0031 - accuracy: 0.9926 - val_loss: 0.0481 - val_accuracy: 0.8967\n",
      "Epoch 478/2000\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.0031 - accuracy: 0.9928 - val_loss: 0.0480 - val_accuracy: 0.8969\n",
      "Epoch 479/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0031 - accuracy: 0.9927 - val_loss: 0.0482 - val_accuracy: 0.8966\n",
      "Epoch 480/2000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0031 - accuracy: 0.9926 - val_loss: 0.0484 - val_accuracy: 0.8961\n",
      "Epoch 481/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0042 - accuracy: 0.9898 - val_loss: 0.0488 - val_accuracy: 0.8952\n",
      "Epoch 482/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0029 - accuracy: 0.9928 - val_loss: 0.0488 - val_accuracy: 0.8952\n",
      "Epoch 483/2000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.0028 - accuracy: 0.9935 - val_loss: 0.0486 - val_accuracy: 0.8954\n",
      "Epoch 484/2000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.0043 - accuracy: 0.9897 - val_loss: 0.0482 - val_accuracy: 0.8962\n",
      "Epoch 485/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0028 - accuracy: 0.9932 - val_loss: 0.0480 - val_accuracy: 0.8967\n",
      "Epoch 486/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0043 - accuracy: 0.9891 - val_loss: 0.0475 - val_accuracy: 0.8976\n",
      "Epoch 487/2000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0025 - accuracy: 0.9945 - val_loss: 0.0474 - val_accuracy: 0.8978\n",
      "Epoch 488/2000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0043 - accuracy: 0.9896 - val_loss: 0.0472 - val_accuracy: 0.8981\n",
      "Epoch 489/2000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.0035 - accuracy: 0.9916 - val_loss: 0.0466 - val_accuracy: 0.8993\n",
      "Epoch 490/2000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.0034 - accuracy: 0.9918 - val_loss: 0.0459 - val_accuracy: 0.9006\n",
      "Epoch 491/2000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0039 - accuracy: 0.9908 - val_loss: 0.0456 - val_accuracy: 0.9011\n",
      "Epoch 492/2000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.0035 - accuracy: 0.9917 - val_loss: 0.0453 - val_accuracy: 0.9016\n",
      "Epoch 493/2000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0039 - accuracy: 0.9900 - val_loss: 0.0451 - val_accuracy: 0.9021\n",
      "Epoch 494/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0031 - accuracy: 0.9929 - val_loss: 0.0451 - val_accuracy: 0.9019\n",
      "Epoch 495/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0030 - accuracy: 0.9929 - val_loss: 0.0453 - val_accuracy: 0.9016\n",
      "Epoch 496/2000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.0033 - accuracy: 0.9921 - val_loss: 0.0454 - val_accuracy: 0.9016\n",
      "Epoch 497/2000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.0028 - accuracy: 0.9938 - val_loss: 0.0458 - val_accuracy: 0.9008\n",
      "Epoch 498/2000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.0039 - accuracy: 0.9907 - val_loss: 0.0462 - val_accuracy: 0.9001\n",
      "Epoch 499/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0045 - accuracy: 0.9891 - val_loss: 0.0463 - val_accuracy: 0.8999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/2000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0032 - accuracy: 0.9928 - val_loss: 0.0470 - val_accuracy: 0.8986\n",
      "Epoch 501/2000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0065 - accuracy: 0.9828 - val_loss: 0.0466 - val_accuracy: 0.8988\n",
      "Epoch 502/2000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0035 - accuracy: 0.9914 - val_loss: 0.0472 - val_accuracy: 0.8968\n",
      "Epoch 503/2000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.0038 - accuracy: 0.9912 - val_loss: 0.0490 - val_accuracy: 0.8927\n",
      "Epoch 504/2000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.0036 - accuracy: 0.9915 - val_loss: 0.0518 - val_accuracy: 0.8869\n",
      "Epoch 505/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0034 - accuracy: 0.9920 - val_loss: 0.0536 - val_accuracy: 0.8830\n",
      "Epoch 506/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0040 - accuracy: 0.9910 - val_loss: 0.0555 - val_accuracy: 0.8790\n",
      "Epoch 507/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0039 - accuracy: 0.9908 - val_loss: 0.0562 - val_accuracy: 0.8776\n",
      "Epoch 508/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0038 - accuracy: 0.9909 - val_loss: 0.0553 - val_accuracy: 0.8796\n",
      "Epoch 509/2000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.0027 - accuracy: 0.9937 - val_loss: 0.0543 - val_accuracy: 0.8818\n",
      "Epoch 510/2000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0028 - accuracy: 0.9930 - val_loss: 0.0537 - val_accuracy: 0.8833\n",
      "Epoch 511/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0035 - accuracy: 0.9918 - val_loss: 0.0527 - val_accuracy: 0.8854\n",
      "Epoch 512/2000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0044 - accuracy: 0.9886 - val_loss: 0.0513 - val_accuracy: 0.8882\n",
      "Epoch 513/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0026 - accuracy: 0.9938 - val_loss: 0.0501 - val_accuracy: 0.8906\n",
      "Epoch 514/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0022 - accuracy: 0.9951 - val_loss: 0.0493 - val_accuracy: 0.8924\n",
      "Epoch 515/2000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.0028 - accuracy: 0.9937 - val_loss: 0.0488 - val_accuracy: 0.8934\n",
      "Epoch 516/2000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.0030 - accuracy: 0.9930 - val_loss: 0.0484 - val_accuracy: 0.8944\n",
      "Epoch 517/2000\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0027 - accuracy: 0.9936 - val_loss: 0.0485 - val_accuracy: 0.8947\n",
      "Epoch 518/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0026 - accuracy: 0.9939 - val_loss: 0.0493 - val_accuracy: 0.8936\n",
      "Epoch 519/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0033 - accuracy: 0.9922 - val_loss: 0.0509 - val_accuracy: 0.8922\n",
      "Epoch 520/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0028 - accuracy: 0.9934 - val_loss: 0.0534 - val_accuracy: 0.8886\n",
      "Epoch 521/2000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.0033 - accuracy: 0.9920 - val_loss: 0.0550 - val_accuracy: 0.8861\n",
      "Epoch 522/2000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.0043 - accuracy: 0.9888 - val_loss: 0.0553 - val_accuracy: 0.8855\n",
      "Epoch 523/2000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.0039 - accuracy: 0.9897 - val_loss: 0.0549 - val_accuracy: 0.8863\n",
      "Epoch 524/2000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0029 - accuracy: 0.9929 - val_loss: 0.0543 - val_accuracy: 0.8873\n",
      "Epoch 525/2000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0043 - accuracy: 0.9898 - val_loss: 0.0540 - val_accuracy: 0.8879\n",
      "Epoch 526/2000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0037 - accuracy: 0.9913 - val_loss: 0.0535 - val_accuracy: 0.8886\n",
      "Epoch 527/2000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.0039 - accuracy: 0.9911 - val_loss: 0.0539 - val_accuracy: 0.8877\n",
      "Epoch 528/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0038 - accuracy: 0.9913 - val_loss: 0.0532 - val_accuracy: 0.8891\n",
      "Epoch 529/2000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.0036 - accuracy: 0.9915 - val_loss: 0.0527 - val_accuracy: 0.8898\n",
      "Epoch 530/2000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0029 - accuracy: 0.9934 - val_loss: 0.0526 - val_accuracy: 0.8898\n",
      "Epoch 531/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0032 - accuracy: 0.9922 - val_loss: 0.0528 - val_accuracy: 0.8891\n",
      "Epoch 532/2000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.0034 - accuracy: 0.9923 - val_loss: 0.0538 - val_accuracy: 0.8870\n",
      "Epoch 533/2000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0046 - accuracy: 0.9882 - val_loss: 0.0545 - val_accuracy: 0.8851\n",
      "Epoch 534/2000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.0048 - accuracy: 0.9871 - val_loss: 0.0549 - val_accuracy: 0.8837\n",
      "Epoch 535/2000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.0036 - accuracy: 0.9909 - val_loss: 0.0549 - val_accuracy: 0.8831\n",
      "Epoch 536/2000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0039 - accuracy: 0.9906 - val_loss: 0.0545 - val_accuracy: 0.8833\n",
      "Epoch 537/2000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.0041 - accuracy: 0.9897 - val_loss: 0.0538 - val_accuracy: 0.8841\n",
      "Epoch 538/2000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.0031 - accuracy: 0.9927 - val_loss: 0.0534 - val_accuracy: 0.8845\n",
      "Epoch 539/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0032 - accuracy: 0.9921 - val_loss: 0.0537 - val_accuracy: 0.8835\n",
      "Epoch 540/2000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.0044 - accuracy: 0.9896 - val_loss: 0.0544 - val_accuracy: 0.8819\n",
      "Epoch 541/2000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.0040 - accuracy: 0.9906 - val_loss: 0.0554 - val_accuracy: 0.8800\n",
      "Epoch 542/2000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0042 - accuracy: 0.9904 - val_loss: 0.0562 - val_accuracy: 0.8787\n",
      "Epoch 543/2000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.0035 - accuracy: 0.9915 - val_loss: 0.0567 - val_accuracy: 0.8780\n",
      "Epoch 544/2000\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.0031 - accuracy: 0.9930 - val_loss: 0.0563 - val_accuracy: 0.8795\n",
      "Epoch 545/2000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0032 - accuracy: 0.9926 - val_loss: 0.0560 - val_accuracy: 0.8808\n",
      "Epoch 546/2000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0026 - accuracy: 0.9935 - val_loss: 0.0560 - val_accuracy: 0.8815\n",
      "Epoch 547/2000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.0041 - accuracy: 0.9896 - val_loss: 0.0555 - val_accuracy: 0.8830\n",
      "Epoch 548/2000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.0025 - accuracy: 0.9936 - val_loss: 0.0550 - val_accuracy: 0.8842\n",
      "Epoch 549/2000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0043 - accuracy: 0.9885 - val_loss: 0.0540 - val_accuracy: 0.8864\n",
      "Epoch 550/2000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0050 - accuracy: 0.9868 - val_loss: 0.0524 - val_accuracy: 0.8893\n",
      "Epoch 551/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0040 - accuracy: 0.9895 - val_loss: 0.0510 - val_accuracy: 0.8919\n",
      "Epoch 552/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0037 - accuracy: 0.9913 - val_loss: 0.0499 - val_accuracy: 0.8940\n",
      "Epoch 553/2000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.0040 - accuracy: 0.9905 - val_loss: 0.0494 - val_accuracy: 0.8949\n",
      "Epoch 554/2000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.0040 - accuracy: 0.9908 - val_loss: 0.0494 - val_accuracy: 0.8949\n",
      "Epoch 555/2000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.0036 - accuracy: 0.9914 - val_loss: 0.0497 - val_accuracy: 0.8945\n",
      "Epoch 556/2000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0044 - accuracy: 0.9899 - val_loss: 0.0505 - val_accuracy: 0.8933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 557/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0040 - accuracy: 0.9900 - val_loss: 0.0513 - val_accuracy: 0.8919\n",
      "Epoch 558/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0035 - accuracy: 0.9914 - val_loss: 0.0522 - val_accuracy: 0.8905\n",
      "Epoch 559/2000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0032 - accuracy: 0.9926 - val_loss: 0.0529 - val_accuracy: 0.8891\n",
      "Epoch 560/2000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.0036 - accuracy: 0.9915 - val_loss: 0.0536 - val_accuracy: 0.8879\n",
      "Epoch 561/2000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.0039 - accuracy: 0.9905 - val_loss: 0.0539 - val_accuracy: 0.8875\n",
      "Epoch 562/2000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0038 - accuracy: 0.9901 - val_loss: 0.0537 - val_accuracy: 0.8877\n",
      "Epoch 563/2000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0035 - accuracy: 0.9916 - val_loss: 0.0532 - val_accuracy: 0.8886\n",
      "Epoch 564/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0040 - accuracy: 0.9898 - val_loss: 0.0521 - val_accuracy: 0.8903\n",
      "Epoch 565/2000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.0030 - accuracy: 0.9926 - val_loss: 0.0508 - val_accuracy: 0.8926\n",
      "Epoch 566/2000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.0030 - accuracy: 0.9925 - val_loss: 0.0493 - val_accuracy: 0.8952\n",
      "Epoch 567/2000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0035 - accuracy: 0.9920 - val_loss: 0.0484 - val_accuracy: 0.8969\n",
      "Epoch 568/2000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0037 - accuracy: 0.9912 - val_loss: 0.0479 - val_accuracy: 0.8976\n",
      "Epoch 569/2000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.0028 - accuracy: 0.9937 - val_loss: 0.0481 - val_accuracy: 0.8973\n",
      "Epoch 570/2000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.0038 - accuracy: 0.9903 - val_loss: 0.0484 - val_accuracy: 0.8965\n",
      "Epoch 571/2000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0034 - accuracy: 0.9917 - val_loss: 0.0486 - val_accuracy: 0.8961\n",
      "Epoch 572/2000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.0029 - accuracy: 0.9931 - val_loss: 0.0489 - val_accuracy: 0.8954\n",
      "Epoch 573/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0030 - accuracy: 0.9929 - val_loss: 0.0492 - val_accuracy: 0.8946\n",
      "Epoch 574/2000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0032 - accuracy: 0.9926 - val_loss: 0.0498 - val_accuracy: 0.8935\n",
      "Epoch 575/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0040 - accuracy: 0.9903 - val_loss: 0.0500 - val_accuracy: 0.8930\n",
      "Epoch 576/2000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0030 - accuracy: 0.9927 - val_loss: 0.0499 - val_accuracy: 0.8931\n",
      "Epoch 577/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0027 - accuracy: 0.9938 - val_loss: 0.0500 - val_accuracy: 0.8929\n",
      "Epoch 578/2000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.0032 - accuracy: 0.9924 - val_loss: 0.0498 - val_accuracy: 0.8934\n",
      "Epoch 579/2000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.0033 - accuracy: 0.9923 - val_loss: 0.0493 - val_accuracy: 0.8944\n",
      "Epoch 580/2000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0034 - accuracy: 0.9922 - val_loss: 0.0487 - val_accuracy: 0.8957\n",
      "Epoch 581/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0027 - accuracy: 0.9933 - val_loss: 0.0484 - val_accuracy: 0.8965\n",
      "Epoch 582/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0031 - accuracy: 0.9929 - val_loss: 0.0485 - val_accuracy: 0.8964\n",
      "Epoch 583/2000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.0038 - accuracy: 0.9904 - val_loss: 0.0482 - val_accuracy: 0.8969\n",
      "Epoch 584/2000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.0028 - accuracy: 0.9931 - val_loss: 0.0478 - val_accuracy: 0.8976\n",
      "Epoch 585/2000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.0025 - accuracy: 0.9937 - val_loss: 0.0475 - val_accuracy: 0.8983\n",
      "Epoch 586/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0034 - accuracy: 0.9918 - val_loss: 0.0471 - val_accuracy: 0.8991\n",
      "Epoch 587/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0029 - accuracy: 0.9929 - val_loss: 0.0469 - val_accuracy: 0.8996\n",
      "Epoch 588/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0034 - accuracy: 0.9917 - val_loss: 0.0465 - val_accuracy: 0.9005\n",
      "Epoch 589/2000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.0027 - accuracy: 0.9935 - val_loss: 0.0463 - val_accuracy: 0.9010\n",
      "Epoch 590/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0032 - accuracy: 0.9928 - val_loss: 0.0465 - val_accuracy: 0.9008\n",
      "Epoch 591/2000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.0031 - accuracy: 0.9925 - val_loss: 0.0470 - val_accuracy: 0.9001\n",
      "Epoch 592/2000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.0029 - accuracy: 0.9929 - val_loss: 0.0472 - val_accuracy: 0.8997\n",
      "Epoch 593/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0033 - accuracy: 0.9921 - val_loss: 0.0471 - val_accuracy: 0.9000\n",
      "Epoch 594/2000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.0021 - accuracy: 0.9950 - val_loss: 0.0473 - val_accuracy: 0.8998\n",
      "Epoch 595/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0037 - accuracy: 0.9901 - val_loss: 0.0468 - val_accuracy: 0.9007\n",
      "Epoch 596/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0029 - accuracy: 0.9929 - val_loss: 0.0464 - val_accuracy: 0.9015\n",
      "Epoch 597/2000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.0025 - accuracy: 0.9941 - val_loss: 0.0458 - val_accuracy: 0.9027\n",
      "Epoch 598/2000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.0029 - accuracy: 0.9934 - val_loss: 0.0452 - val_accuracy: 0.9036\n",
      "Epoch 599/2000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0035 - accuracy: 0.9915 - val_loss: 0.0449 - val_accuracy: 0.9041\n",
      "Epoch 600/2000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0025 - accuracy: 0.9943 - val_loss: 0.0448 - val_accuracy: 0.9041\n",
      "Epoch 601/2000\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0029 - accuracy: 0.9929 - val_loss: 0.0450 - val_accuracy: 0.9038\n",
      "Epoch 602/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0030 - accuracy: 0.9927 - val_loss: 0.0451 - val_accuracy: 0.9035\n",
      "Epoch 603/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0026 - accuracy: 0.9937 - val_loss: 0.0451 - val_accuracy: 0.9033\n",
      "Epoch 604/2000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.0023 - accuracy: 0.9945 - val_loss: 0.0456 - val_accuracy: 0.9025\n",
      "Epoch 605/2000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.0024 - accuracy: 0.9944 - val_loss: 0.0462 - val_accuracy: 0.9015\n",
      "Epoch 606/2000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0044 - accuracy: 0.9885 - val_loss: 0.0461 - val_accuracy: 0.9015\n",
      "Epoch 607/2000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.0023 - accuracy: 0.9946 - val_loss: 0.0460 - val_accuracy: 0.9016\n",
      "Epoch 608/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0033 - accuracy: 0.9911 - val_loss: 0.0456 - val_accuracy: 0.9021\n",
      "Epoch 609/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0033 - accuracy: 0.9916 - val_loss: 0.0450 - val_accuracy: 0.9030\n",
      "Epoch 610/2000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.0025 - accuracy: 0.9940 - val_loss: 0.0445 - val_accuracy: 0.9037\n",
      "Epoch 611/2000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.0029 - accuracy: 0.9935 - val_loss: 0.0443 - val_accuracy: 0.9040\n",
      "Epoch 612/2000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.0031 - accuracy: 0.9930 - val_loss: 0.0446 - val_accuracy: 0.9035\n",
      "Epoch 613/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0032 - accuracy: 0.9924 - val_loss: 0.0449 - val_accuracy: 0.9030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 614/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0027 - accuracy: 0.9938 - val_loss: 0.0453 - val_accuracy: 0.9022\n",
      "Epoch 615/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0026 - accuracy: 0.9938 - val_loss: 0.0461 - val_accuracy: 0.9010\n",
      "Epoch 616/2000\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0028 - accuracy: 0.9932 - val_loss: 0.0467 - val_accuracy: 0.9001\n",
      "Epoch 617/2000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.0033 - accuracy: 0.9914 - val_loss: 0.0470 - val_accuracy: 0.8995\n",
      "Epoch 618/2000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0029 - accuracy: 0.9925 - val_loss: 0.0472 - val_accuracy: 0.8993\n",
      "Epoch 619/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0027 - accuracy: 0.9933 - val_loss: 0.0474 - val_accuracy: 0.8991\n",
      "Epoch 620/2000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.0027 - accuracy: 0.9931 - val_loss: 0.0474 - val_accuracy: 0.8991\n",
      "Epoch 621/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0036 - accuracy: 0.9908 - val_loss: 0.0470 - val_accuracy: 0.8998\n",
      "Epoch 622/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0034 - accuracy: 0.9917 - val_loss: 0.0467 - val_accuracy: 0.9004\n",
      "Epoch 623/2000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.0029 - accuracy: 0.9932 - val_loss: 0.0463 - val_accuracy: 0.9012\n",
      "Epoch 624/2000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.0032 - accuracy: 0.9923 - val_loss: 0.0461 - val_accuracy: 0.9015\n",
      "Epoch 625/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0030 - accuracy: 0.9930 - val_loss: 0.0462 - val_accuracy: 0.9013\n",
      "Epoch 626/2000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0029 - accuracy: 0.9935 - val_loss: 0.0464 - val_accuracy: 0.9009\n",
      "Epoch 627/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0030 - accuracy: 0.9929 - val_loss: 0.0469 - val_accuracy: 0.9000\n",
      "Epoch 628/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0023 - accuracy: 0.9946 - val_loss: 0.0475 - val_accuracy: 0.8990\n",
      "Epoch 629/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0026 - accuracy: 0.9943 - val_loss: 0.0479 - val_accuracy: 0.8983\n",
      "Epoch 630/2000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.0022 - accuracy: 0.9946 - val_loss: 0.0482 - val_accuracy: 0.8977\n",
      "Epoch 631/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0033 - accuracy: 0.9916 - val_loss: 0.0477 - val_accuracy: 0.8985\n",
      "Epoch 632/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0027 - accuracy: 0.9929 - val_loss: 0.0472 - val_accuracy: 0.8994\n",
      "Epoch 633/2000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.0030 - accuracy: 0.9926 - val_loss: 0.0465 - val_accuracy: 0.9006\n",
      "Epoch 634/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0030 - accuracy: 0.9924 - val_loss: 0.0455 - val_accuracy: 0.9024\n",
      "Epoch 635/2000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.0030 - accuracy: 0.9929 - val_loss: 0.0448 - val_accuracy: 0.9037\n",
      "Epoch 636/2000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.0027 - accuracy: 0.9933 - val_loss: 0.0442 - val_accuracy: 0.9048\n",
      "Epoch 637/2000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0029 - accuracy: 0.9938 - val_loss: 0.0440 - val_accuracy: 0.9050\n",
      "Epoch 638/2000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0025 - accuracy: 0.9944 - val_loss: 0.0442 - val_accuracy: 0.9047\n",
      "Epoch 639/2000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0038 - accuracy: 0.9913 - val_loss: 0.0449 - val_accuracy: 0.9036\n",
      "Epoch 640/2000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.0027 - accuracy: 0.9939 - val_loss: 0.0456 - val_accuracy: 0.9022\n",
      "Epoch 641/2000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0039 - accuracy: 0.9912 - val_loss: 0.0466 - val_accuracy: 0.9007\n",
      "Epoch 642/2000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0025 - accuracy: 0.9942 - val_loss: 0.0474 - val_accuracy: 0.8993\n",
      "Epoch 643/2000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.0024 - accuracy: 0.9936 - val_loss: 0.0479 - val_accuracy: 0.8985\n",
      "Epoch 644/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0039 - accuracy: 0.9900 - val_loss: 0.0479 - val_accuracy: 0.8985\n",
      "Epoch 645/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0034 - accuracy: 0.9909 - val_loss: 0.0472 - val_accuracy: 0.8998\n",
      "Epoch 646/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0031 - accuracy: 0.9925 - val_loss: 0.0464 - val_accuracy: 0.9013\n",
      "Epoch 647/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0022 - accuracy: 0.9948 - val_loss: 0.0456 - val_accuracy: 0.9027\n",
      "Epoch 648/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0024 - accuracy: 0.9947 - val_loss: 0.0449 - val_accuracy: 0.9042\n",
      "Epoch 649/2000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.0028 - accuracy: 0.9937 - val_loss: 0.0443 - val_accuracy: 0.9050\n",
      "Epoch 650/2000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0030 - accuracy: 0.9935 - val_loss: 0.0442 - val_accuracy: 0.9052\n",
      "Epoch 651/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0029 - accuracy: 0.9931 - val_loss: 0.0442 - val_accuracy: 0.9053\n",
      "Epoch 652/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0026 - accuracy: 0.9940 - val_loss: 0.0443 - val_accuracy: 0.9051\n",
      "Epoch 653/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0030 - accuracy: 0.9926 - val_loss: 0.0446 - val_accuracy: 0.9046\n",
      "Epoch 654/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0024 - accuracy: 0.9943 - val_loss: 0.0451 - val_accuracy: 0.9037\n",
      "Epoch 655/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0027 - accuracy: 0.9936 - val_loss: 0.0456 - val_accuracy: 0.9028\n",
      "Epoch 656/2000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.0022 - accuracy: 0.9951 - val_loss: 0.0463 - val_accuracy: 0.9017\n",
      "Epoch 657/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0026 - accuracy: 0.9935 - val_loss: 0.0466 - val_accuracy: 0.9009\n",
      "Epoch 658/2000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0029 - accuracy: 0.9922 - val_loss: 0.0464 - val_accuracy: 0.9013\n",
      "Epoch 659/2000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0035 - accuracy: 0.9906 - val_loss: 0.0457 - val_accuracy: 0.9024\n",
      "Epoch 660/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0029 - accuracy: 0.9928 - val_loss: 0.0449 - val_accuracy: 0.9038\n",
      "Epoch 661/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0028 - accuracy: 0.9938 - val_loss: 0.0443 - val_accuracy: 0.9048\n",
      "Epoch 662/2000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.0030 - accuracy: 0.9934 - val_loss: 0.0442 - val_accuracy: 0.9049\n",
      "Epoch 663/2000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.0028 - accuracy: 0.9933 - val_loss: 0.0442 - val_accuracy: 0.9049\n",
      "Epoch 664/2000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.0028 - accuracy: 0.9937 - val_loss: 0.0445 - val_accuracy: 0.9044\n",
      "Epoch 665/2000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.0024 - accuracy: 0.9949 - val_loss: 0.0449 - val_accuracy: 0.9037\n",
      "Epoch 666/2000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.0024 - accuracy: 0.9941 - val_loss: 0.0452 - val_accuracy: 0.9031\n",
      "Epoch 667/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0022 - accuracy: 0.9948 - val_loss: 0.0454 - val_accuracy: 0.9027\n",
      "Epoch 668/2000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.0025 - accuracy: 0.9941 - val_loss: 0.0456 - val_accuracy: 0.9023\n",
      "Epoch 669/2000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0021 - accuracy: 0.9945 - val_loss: 0.0458 - val_accuracy: 0.9020\n",
      "Epoch 670/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0030 - accuracy: 0.9921 - val_loss: 0.0454 - val_accuracy: 0.9026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 671/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0033 - accuracy: 0.9916 - val_loss: 0.0451 - val_accuracy: 0.9034\n",
      "Epoch 672/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0023 - accuracy: 0.9944 - val_loss: 0.0447 - val_accuracy: 0.9040\n",
      "Epoch 673/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0022 - accuracy: 0.9945 - val_loss: 0.0443 - val_accuracy: 0.9048\n",
      "Epoch 674/2000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0025 - accuracy: 0.9940 - val_loss: 0.0439 - val_accuracy: 0.9053\n",
      "Epoch 675/2000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.0026 - accuracy: 0.9942 - val_loss: 0.0436 - val_accuracy: 0.9059\n",
      "Epoch 676/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0021 - accuracy: 0.9952 - val_loss: 0.0433 - val_accuracy: 0.9065\n",
      "Epoch 677/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0027 - accuracy: 0.9939 - val_loss: 0.0431 - val_accuracy: 0.9068\n",
      "Epoch 678/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0032 - accuracy: 0.9926 - val_loss: 0.0433 - val_accuracy: 0.9064\n",
      "Epoch 679/2000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0029 - accuracy: 0.9931 - val_loss: 0.0438 - val_accuracy: 0.9055\n",
      "Epoch 680/2000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.0025 - accuracy: 0.9942 - val_loss: 0.0443 - val_accuracy: 0.9047\n",
      "Epoch 681/2000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.0038 - accuracy: 0.9901 - val_loss: 0.0446 - val_accuracy: 0.9042\n",
      "Epoch 682/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0023 - accuracy: 0.9944 - val_loss: 0.0446 - val_accuracy: 0.9041\n",
      "Epoch 683/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0024 - accuracy: 0.9945 - val_loss: 0.0444 - val_accuracy: 0.9045\n",
      "Epoch 684/2000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0030 - accuracy: 0.9920 - val_loss: 0.0440 - val_accuracy: 0.9050\n",
      "Epoch 685/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0021 - accuracy: 0.9955 - val_loss: 0.0439 - val_accuracy: 0.9052\n",
      "Epoch 686/2000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.0030 - accuracy: 0.9929 - val_loss: 0.0438 - val_accuracy: 0.9055\n",
      "Epoch 687/2000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.0022 - accuracy: 0.9950 - val_loss: 0.0437 - val_accuracy: 0.9055\n",
      "Epoch 688/2000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.0018 - accuracy: 0.9957 - val_loss: 0.0437 - val_accuracy: 0.9057\n",
      "Epoch 689/2000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0018 - accuracy: 0.9960 - val_loss: 0.0438 - val_accuracy: 0.9055\n",
      "Epoch 690/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0023 - accuracy: 0.9948 - val_loss: 0.0443 - val_accuracy: 0.9046\n",
      "Epoch 691/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0039 - accuracy: 0.9899 - val_loss: 0.0442 - val_accuracy: 0.9050\n",
      "Epoch 692/2000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0023 - accuracy: 0.9943 - val_loss: 0.0439 - val_accuracy: 0.9055\n",
      "Epoch 693/2000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.0021 - accuracy: 0.9948 - val_loss: 0.0436 - val_accuracy: 0.9060\n",
      "Epoch 694/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0026 - accuracy: 0.9935 - val_loss: 0.0434 - val_accuracy: 0.9065\n",
      "Epoch 695/2000\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0025 - accuracy: 0.9943 - val_loss: 0.0432 - val_accuracy: 0.9068\n",
      "Epoch 696/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0027 - accuracy: 0.9938 - val_loss: 0.0430 - val_accuracy: 0.9073\n",
      "Epoch 697/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0025 - accuracy: 0.9946 - val_loss: 0.0428 - val_accuracy: 0.9076\n",
      "Epoch 698/2000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.0024 - accuracy: 0.9948 - val_loss: 0.0429 - val_accuracy: 0.9077\n",
      "Epoch 699/2000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0021 - accuracy: 0.9945 - val_loss: 0.0429 - val_accuracy: 0.9077\n",
      "Epoch 700/2000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.0032 - accuracy: 0.9915 - val_loss: 0.0424 - val_accuracy: 0.9086\n",
      "Epoch 701/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0024 - accuracy: 0.9942 - val_loss: 0.0421 - val_accuracy: 0.9093\n",
      "Epoch 702/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0028 - accuracy: 0.9930 - val_loss: 0.0417 - val_accuracy: 0.9099\n",
      "Epoch 703/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0024 - accuracy: 0.9941 - val_loss: 0.0414 - val_accuracy: 0.9106\n",
      "Epoch 704/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0022 - accuracy: 0.9950 - val_loss: 0.0412 - val_accuracy: 0.9110\n",
      "Epoch 705/2000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.0022 - accuracy: 0.9945 - val_loss: 0.0409 - val_accuracy: 0.9113\n",
      "Epoch 706/2000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.0027 - accuracy: 0.9933 - val_loss: 0.0407 - val_accuracy: 0.9116\n",
      "Epoch 707/2000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.0028 - accuracy: 0.9928 - val_loss: 0.0406 - val_accuracy: 0.9118\n",
      "Epoch 708/2000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0024 - accuracy: 0.9943 - val_loss: 0.0404 - val_accuracy: 0.9119\n",
      "Epoch 709/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0028 - accuracy: 0.9934 - val_loss: 0.0404 - val_accuracy: 0.9118\n",
      "Epoch 710/2000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0024 - accuracy: 0.9950 - val_loss: 0.0406 - val_accuracy: 0.9115\n",
      "Epoch 711/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0027 - accuracy: 0.9942 - val_loss: 0.0408 - val_accuracy: 0.9112\n",
      "Epoch 712/2000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0023 - accuracy: 0.9947 - val_loss: 0.0410 - val_accuracy: 0.9107\n",
      "Epoch 713/2000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.0022 - accuracy: 0.9946 - val_loss: 0.0412 - val_accuracy: 0.9104\n",
      "Epoch 714/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0022 - accuracy: 0.9946 - val_loss: 0.0412 - val_accuracy: 0.9105\n",
      "Epoch 715/2000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.0021 - accuracy: 0.9950 - val_loss: 0.0415 - val_accuracy: 0.9100\n",
      "Epoch 716/2000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0024 - accuracy: 0.9942 - val_loss: 0.0418 - val_accuracy: 0.9094\n",
      "Epoch 717/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0019 - accuracy: 0.9954 - val_loss: 0.0423 - val_accuracy: 0.9086\n",
      "Epoch 718/2000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0024 - accuracy: 0.9944 - val_loss: 0.0430 - val_accuracy: 0.9075\n",
      "Epoch 719/2000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.0029 - accuracy: 0.9926 - val_loss: 0.0435 - val_accuracy: 0.9067\n",
      "Epoch 720/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0026 - accuracy: 0.9936 - val_loss: 0.0437 - val_accuracy: 0.9063\n",
      "Epoch 721/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0027 - accuracy: 0.9931 - val_loss: 0.0436 - val_accuracy: 0.9065\n",
      "Epoch 722/2000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0031 - accuracy: 0.9918 - val_loss: 0.0435 - val_accuracy: 0.9068\n",
      "Epoch 723/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0020 - accuracy: 0.9955 - val_loss: 0.0432 - val_accuracy: 0.9073\n",
      "Epoch 724/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0035 - accuracy: 0.9925 - val_loss: 0.0433 - val_accuracy: 0.9072\n",
      "Epoch 725/2000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.0025 - accuracy: 0.9942 - val_loss: 0.0435 - val_accuracy: 0.9068\n",
      "Epoch 726/2000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0025 - accuracy: 0.9945 - val_loss: 0.0437 - val_accuracy: 0.9065\n",
      "Epoch 727/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0026 - accuracy: 0.9941 - val_loss: 0.0440 - val_accuracy: 0.9058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 728/2000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.0021 - accuracy: 0.9951 - val_loss: 0.0444 - val_accuracy: 0.9050\n",
      "Epoch 729/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0021 - accuracy: 0.9948 - val_loss: 0.0447 - val_accuracy: 0.9043\n",
      "Epoch 730/2000\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0023 - accuracy: 0.9940 - val_loss: 0.0447 - val_accuracy: 0.9043\n",
      "Epoch 731/2000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0044 - accuracy: 0.9881 - val_loss: 0.0437 - val_accuracy: 0.9062\n",
      "Epoch 732/2000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0024 - accuracy: 0.9944 - val_loss: 0.0430 - val_accuracy: 0.9075\n",
      "Epoch 733/2000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0023 - accuracy: 0.9944 - val_loss: 0.0424 - val_accuracy: 0.9085\n",
      "Epoch 734/2000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.0025 - accuracy: 0.9939 - val_loss: 0.0420 - val_accuracy: 0.9094\n",
      "Epoch 735/2000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.0020 - accuracy: 0.9955 - val_loss: 0.0418 - val_accuracy: 0.9097\n",
      "Epoch 736/2000\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0020 - accuracy: 0.9956 - val_loss: 0.0418 - val_accuracy: 0.9097\n",
      "Epoch 737/2000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0022 - accuracy: 0.9946 - val_loss: 0.0420 - val_accuracy: 0.9094\n",
      "Epoch 738/2000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.0025 - accuracy: 0.9940 - val_loss: 0.0421 - val_accuracy: 0.9092\n",
      "Epoch 739/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0022 - accuracy: 0.9950 - val_loss: 0.0422 - val_accuracy: 0.9090\n",
      "Epoch 740/2000\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0022 - accuracy: 0.9950 - val_loss: 0.0424 - val_accuracy: 0.9087\n",
      "Epoch 741/2000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.0026 - accuracy: 0.9937 - val_loss: 0.0428 - val_accuracy: 0.9080\n",
      "Epoch 742/2000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0023 - accuracy: 0.9946 - val_loss: 0.0433 - val_accuracy: 0.9072\n",
      "Epoch 743/2000\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0019 - accuracy: 0.9955 - val_loss: 0.0436 - val_accuracy: 0.9067\n",
      "Epoch 744/2000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.0023 - accuracy: 0.9941 - val_loss: 0.0435 - val_accuracy: 0.9069\n",
      "Epoch 745/2000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0020 - accuracy: 0.9948 - val_loss: 0.0433 - val_accuracy: 0.9074\n",
      "Epoch 746/2000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.0019 - accuracy: 0.9953 - val_loss: 0.0429 - val_accuracy: 0.9082\n",
      "Epoch 747/2000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0024 - accuracy: 0.9947 - val_loss: 0.0426 - val_accuracy: 0.9089\n",
      "Epoch 748/2000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0021 - accuracy: 0.9946 - val_loss: 0.0421 - val_accuracy: 0.9099\n",
      "Epoch 749/2000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0022 - accuracy: 0.9951 - val_loss: 0.0421 - val_accuracy: 0.9101\n",
      "Epoch 750/2000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.0020 - accuracy: 0.9952 - val_loss: 0.0422 - val_accuracy: 0.9100\n",
      "Epoch 751/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0035 - accuracy: 0.9909 - val_loss: 0.0421 - val_accuracy: 0.9100\n",
      "Epoch 752/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0024 - accuracy: 0.9942 - val_loss: 0.0421 - val_accuracy: 0.9100\n",
      "Epoch 753/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0022 - accuracy: 0.9950 - val_loss: 0.0424 - val_accuracy: 0.9095\n",
      "Epoch 754/2000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.0020 - accuracy: 0.9951 - val_loss: 0.0427 - val_accuracy: 0.9090\n",
      "Epoch 755/2000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.0019 - accuracy: 0.9953 - val_loss: 0.0429 - val_accuracy: 0.9084\n",
      "Epoch 756/2000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0016 - accuracy: 0.9962 - val_loss: 0.0434 - val_accuracy: 0.9076\n",
      "Epoch 757/2000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0022 - accuracy: 0.9945 - val_loss: 0.0437 - val_accuracy: 0.9070\n",
      "Epoch 758/2000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0022 - accuracy: 0.9952 - val_loss: 0.0441 - val_accuracy: 0.9062\n",
      "Epoch 759/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0023 - accuracy: 0.9945 - val_loss: 0.0441 - val_accuracy: 0.9062\n",
      "Epoch 760/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0028 - accuracy: 0.9936 - val_loss: 0.0438 - val_accuracy: 0.9068\n",
      "Epoch 761/2000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0018 - accuracy: 0.9958 - val_loss: 0.0434 - val_accuracy: 0.9076\n",
      "Epoch 762/2000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0019 - accuracy: 0.9958 - val_loss: 0.0430 - val_accuracy: 0.9083\n",
      "Epoch 763/2000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0026 - accuracy: 0.9939 - val_loss: 0.0424 - val_accuracy: 0.9094\n",
      "Epoch 764/2000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0018 - accuracy: 0.9958 - val_loss: 0.0420 - val_accuracy: 0.9100\n",
      "Epoch 765/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0015 - accuracy: 0.9962 - val_loss: 0.0417 - val_accuracy: 0.9104\n",
      "Epoch 766/2000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0020 - accuracy: 0.9953 - val_loss: 0.0417 - val_accuracy: 0.9104\n",
      "Epoch 767/2000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0023 - accuracy: 0.9946 - val_loss: 0.0417 - val_accuracy: 0.9104\n",
      "Epoch 768/2000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.0020 - accuracy: 0.9953 - val_loss: 0.0418 - val_accuracy: 0.9103\n",
      "Epoch 769/2000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0018 - accuracy: 0.9957 - val_loss: 0.0417 - val_accuracy: 0.9105\n",
      "Epoch 770/2000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.0025 - accuracy: 0.9937 - val_loss: 0.0414 - val_accuracy: 0.9111\n",
      "Epoch 771/2000\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0022 - accuracy: 0.9947 - val_loss: 0.0412 - val_accuracy: 0.9114\n",
      "Epoch 772/2000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0024 - accuracy: 0.9944 - val_loss: 0.0410 - val_accuracy: 0.9119\n",
      "Epoch 773/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0019 - accuracy: 0.9960 - val_loss: 0.0408 - val_accuracy: 0.9120\n",
      "Epoch 774/2000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.0016 - accuracy: 0.9964 - val_loss: 0.0409 - val_accuracy: 0.9119\n",
      "Epoch 775/2000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0022 - accuracy: 0.9947 - val_loss: 0.0412 - val_accuracy: 0.9113\n",
      "Epoch 776/2000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.0020 - accuracy: 0.9952 - val_loss: 0.0414 - val_accuracy: 0.9108\n",
      "Epoch 777/2000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0020 - accuracy: 0.9957 - val_loss: 0.0419 - val_accuracy: 0.9099\n",
      "Epoch 778/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0027 - accuracy: 0.9930 - val_loss: 0.0421 - val_accuracy: 0.9096\n",
      "Epoch 779/2000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0022 - accuracy: 0.9945 - val_loss: 0.0419 - val_accuracy: 0.9098\n",
      "Epoch 780/2000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.0021 - accuracy: 0.9954 - val_loss: 0.0417 - val_accuracy: 0.9101\n",
      "Epoch 781/2000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0018 - accuracy: 0.9958 - val_loss: 0.0415 - val_accuracy: 0.9106\n",
      "Epoch 782/2000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.0017 - accuracy: 0.9957 - val_loss: 0.0412 - val_accuracy: 0.9110\n",
      "Epoch 783/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0016 - accuracy: 0.9964 - val_loss: 0.0411 - val_accuracy: 0.9113\n",
      "Epoch 784/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0021 - accuracy: 0.9954 - val_loss: 0.0411 - val_accuracy: 0.9114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0019 - accuracy: 0.9956 - val_loss: 0.0417 - val_accuracy: 0.9103\n",
      "Epoch 786/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0023 - accuracy: 0.9940 - val_loss: 0.0422 - val_accuracy: 0.9095\n",
      "Epoch 787/2000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0022 - accuracy: 0.9946 - val_loss: 0.0428 - val_accuracy: 0.9086\n",
      "Epoch 788/2000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0015 - accuracy: 0.9962 - val_loss: 0.0434 - val_accuracy: 0.9076\n",
      "Epoch 789/2000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0015 - accuracy: 0.9963 - val_loss: 0.0438 - val_accuracy: 0.9069\n",
      "Epoch 790/2000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0021 - accuracy: 0.9951 - val_loss: 0.0440 - val_accuracy: 0.9065\n",
      "Epoch 791/2000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0029 - accuracy: 0.9927 - val_loss: 0.0441 - val_accuracy: 0.9064\n",
      "Epoch 792/2000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0016 - accuracy: 0.9963 - val_loss: 0.0441 - val_accuracy: 0.9065\n",
      "Epoch 793/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0026 - accuracy: 0.9935 - val_loss: 0.0436 - val_accuracy: 0.9073\n",
      "Epoch 794/2000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.0021 - accuracy: 0.9953 - val_loss: 0.0435 - val_accuracy: 0.9075\n",
      "Epoch 795/2000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.0023 - accuracy: 0.9948 - val_loss: 0.0433 - val_accuracy: 0.9076\n",
      "Epoch 796/2000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0022 - accuracy: 0.9950 - val_loss: 0.0432 - val_accuracy: 0.9078\n",
      "Epoch 797/2000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0021 - accuracy: 0.9953 - val_loss: 0.0434 - val_accuracy: 0.9075\n",
      "Epoch 798/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0030 - accuracy: 0.9921 - val_loss: 0.0433 - val_accuracy: 0.9076\n",
      "Epoch 799/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0017 - accuracy: 0.9957 - val_loss: 0.0431 - val_accuracy: 0.9078\n",
      "Epoch 800/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0020 - accuracy: 0.9948 - val_loss: 0.0427 - val_accuracy: 0.9085\n",
      "Epoch 801/2000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.0020 - accuracy: 0.9948 - val_loss: 0.0425 - val_accuracy: 0.9090\n",
      "Epoch 802/2000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.0024 - accuracy: 0.9943 - val_loss: 0.0423 - val_accuracy: 0.9092\n",
      "Epoch 803/2000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0027 - accuracy: 0.9935 - val_loss: 0.0424 - val_accuracy: 0.9091\n",
      "Epoch 804/2000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0020 - accuracy: 0.9952 - val_loss: 0.0426 - val_accuracy: 0.9089\n",
      "Epoch 805/2000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.0029 - accuracy: 0.9933 - val_loss: 0.0428 - val_accuracy: 0.9086\n",
      "Epoch 806/2000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0018 - accuracy: 0.9959 - val_loss: 0.0431 - val_accuracy: 0.9082\n",
      "Epoch 807/2000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.0017 - accuracy: 0.9963 - val_loss: 0.0434 - val_accuracy: 0.9078\n",
      "Epoch 808/2000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.0017 - accuracy: 0.9960 - val_loss: 0.0436 - val_accuracy: 0.9077\n",
      "Epoch 809/2000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0021 - accuracy: 0.9950 - val_loss: 0.0436 - val_accuracy: 0.9077\n",
      "Epoch 810/2000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0023 - accuracy: 0.9942 - val_loss: 0.0436 - val_accuracy: 0.9078\n",
      "Epoch 811/2000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0018 - accuracy: 0.9958 - val_loss: 0.0436 - val_accuracy: 0.9078\n",
      "Epoch 812/2000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0024 - accuracy: 0.9941 - val_loss: 0.0435 - val_accuracy: 0.9080\n",
      "Epoch 813/2000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0017 - accuracy: 0.9960 - val_loss: 0.0435 - val_accuracy: 0.9080\n",
      "Epoch 814/2000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.0019 - accuracy: 0.9958 - val_loss: 0.0438 - val_accuracy: 0.9074\n",
      "Epoch 815/2000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0021 - accuracy: 0.9949 - val_loss: 0.0439 - val_accuracy: 0.9070\n",
      "Epoch 816/2000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0016 - accuracy: 0.9965 - val_loss: 0.0442 - val_accuracy: 0.9065\n",
      "Epoch 817/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0017 - accuracy: 0.9959 - val_loss: 0.0443 - val_accuracy: 0.9062\n",
      "Epoch 818/2000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0021 - accuracy: 0.9949 - val_loss: 0.0443 - val_accuracy: 0.9062\n",
      "Epoch 819/2000\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0018 - accuracy: 0.9961 - val_loss: 0.0442 - val_accuracy: 0.9063\n",
      "Epoch 820/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0019 - accuracy: 0.9954 - val_loss: 0.0440 - val_accuracy: 0.9066\n",
      "Epoch 821/2000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.0014 - accuracy: 0.9967 - val_loss: 0.0438 - val_accuracy: 0.9070\n",
      "Epoch 822/2000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0019 - accuracy: 0.9955 - val_loss: 0.0437 - val_accuracy: 0.9072\n",
      "Epoch 823/2000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0018 - accuracy: 0.9956 - val_loss: 0.0437 - val_accuracy: 0.9073\n",
      "Epoch 824/2000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0013 - accuracy: 0.9968 - val_loss: 0.0437 - val_accuracy: 0.9072\n",
      "Epoch 825/2000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0020 - accuracy: 0.9950 - val_loss: 0.0435 - val_accuracy: 0.9076\n",
      "Epoch 826/2000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0024 - accuracy: 0.9940 - val_loss: 0.0431 - val_accuracy: 0.9084\n",
      "Epoch 827/2000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0019 - accuracy: 0.9956 - val_loss: 0.0429 - val_accuracy: 0.9089\n",
      "Epoch 828/2000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.0024 - accuracy: 0.9941 - val_loss: 0.0424 - val_accuracy: 0.9099\n",
      "Epoch 829/2000\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.0023 - accuracy: 0.9946 - val_loss: 0.0417 - val_accuracy: 0.9111\n",
      "Epoch 830/2000\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0020 - accuracy: 0.9957 - val_loss: 0.0414 - val_accuracy: 0.9118\n",
      "Epoch 831/2000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9957"
     ]
    }
   ],
   "source": [
    "image = sliceVolumeImage(train_images)       \n",
    "mask = tf.math.round(sliceVolumeImage(train_labels))\n",
    "val_image = sliceVolumeImage(test_images)       \n",
    "val_mask = tf.math.round(sliceVolumeImage(test_labels))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss = loss_fn, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(image, mask, validation_data=(val_image, val_mask),\n",
    "                  batch_size=32,\n",
    "                  epochs=NUM_OF_EPOCHS, steps_per_epoch=1,\n",
    "                  callbacks=[earlyStopping,tensorboard_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PATH +'/segmentation2d/' + name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
