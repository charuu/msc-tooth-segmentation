{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jain0000/miniconda3/envs/segment2/lib/python3.7/site-packages/dicom/__init__.py:53: UserWarning: \n",
      "This code is using an older version of pydicom, which is no longer \n",
      "maintained as of Jan 2017.  You can access the new pydicom features and API \n",
      "by installing `pydicom` from PyPI.\n",
      "See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org \n",
      "for more information.\n",
      "\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 952815119362853527\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9300830896616399583\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 344716196583261504\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 5496508970366910545\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:2\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13722377508581713935\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 542507008\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1137522105475881845\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2061893632\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 4116825692455224994\n",
      "physical_device_desc: \"device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:2\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10883057600\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 4885259100288347721\n",
      "physical_device_desc: \"device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from niwidgets import NiftiWidget\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import * \n",
    "from tensorflow import keras\n",
    "from config import *\n",
    "from modelIO import *\n",
    "from model import *\n",
    "from display import *\n",
    "from dataAugmentation import *\n",
    "from segmentation import *\n",
    "from skimage.util import montage, crop\n",
    "from skimage import data, color\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "from numpy import fliplr\n",
    "from datetime import *\n",
    "#import tensorflow.experimental.numpy as tnp\n",
    "#print(device_lib.list_local_devices())\n",
    "print(device_lib.list_local_devices())\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "Current Time = 19:54:02\n",
      "mandible-Right-Molar\n",
      "mandible-Right-Molar/iteration1\n",
      "mandible-Right-Molar/iteration1\n",
      "mandible-Right-Molar/iteration1\n",
      "mandible-Right-Molar/iteration1\n",
      "mandible-Right-Molar/iteration1\n",
      "mandible-Right-Molar\n",
      "mandible-Right-Molar/iteration2\n",
      "mandible-Right-Molar/iteration2\n",
      "mandible-Right-Molar/iteration2\n",
      "mandible-Right-Molar/iteration2\n",
      "mandible-Right-Molar/iteration2\n",
      "mandible-Right-Molar\n",
      "mandible-Right-Molar/iteration3\n",
      "mandible-Right-Molar/iteration3\n",
      "mandible-Right-Molar/iteration3\n",
      "mandible-Right-Molar/iteration3\n",
      "mandible-Right-Molar/iteration3\n",
      "mandible-Right-Molar\n",
      "mandible-Right-Molar/iteration4\n",
      "mandible-Right-Molar/iteration4\n",
      "mandible-Right-Molar/iteration4\n",
      "mandible-Right-Molar/iteration4\n",
      "mandible-Right-Molar/iteration4\n",
      "mandible-Right-Canine\n",
      "mandible-Right-Canine/iteration1\n",
      "mandible-Right-Canine/iteration1\n",
      "mandible-Right-Canine/iteration1\n",
      "mandible-Right-Canine/iteration1\n",
      "mandible-Right-Canine/iteration1\n",
      "mandible-Right-Canine\n",
      "mandible-Right-Canine/iteration3\n",
      "mandible-Right-Canine/iteration3\n",
      "mandible-Right-Canine/iteration3\n",
      "mandible-Right-Canine/iteration3\n",
      "mandible-Right-Canine/iteration3\n",
      "maxilla-Right-Molar\n",
      "maxilla-Right-Molar/iteration1\n",
      "maxilla-Right-Molar/iteration1\n",
      "maxilla-Right-Molar/iteration1\n",
      "maxilla-Right-Molar/iteration1\n",
      "maxilla-Right-Molar/iteration1\n",
      "maxilla-Right-Molar\n",
      "maxilla-Right-Molar/iteration2\n",
      "maxilla-Right-Molar/iteration2\n",
      "maxilla-Right-Molar/iteration2\n",
      "maxilla-Right-Molar/iteration2\n",
      "maxilla-Right-Molar/iteration2\n",
      "mandible-Right-Canine\n",
      "mandible-Right-Canine/iteration2\n",
      "mandible-Right-Canine/iteration2\n",
      "mandible-Right-Canine/iteration2\n",
      "mandible-Right-Canine/iteration2\n",
      "mandible-Right-Canine/iteration2\n",
      "mandible-Right-Canine/iteration2\n",
      "mandible-Right-Canine/iteration2\n",
      "mandible-Right-Canine/iteration2\n",
      "mandible-Right-Canine/iteration2\n",
      "mandible-Right-Canine/iteration2\n",
      "mandible-Right-Canine\n",
      "mandible-Right-Molar\n",
      "maxilla-Left-Canine\n",
      "mandible-Right-Premolar\n",
      "maxilla-Right-Canine\n",
      "mandible-Left-Molar\n",
      "maxilla-Left-Premolar\n",
      "maxilla-Left-Incisor\n",
      "mandible-Left-Incisor\n",
      "mandible-Right-Incisor\n",
      "maxilla-Right-Premolar\n",
      "maxilla-Left-Molar\n",
      "maxilla-Right-Incisor\n",
      "mandible-Left-Premolar\n",
      "maxilla-Right-Molar\n",
      "mandible-Left-Canine\n",
      "(50, 40, 40, 40) (50, 40, 40, 40) (16, 40, 40, 40) (16, 40, 40, 40)\n",
      "WARNING:tensorflow:AutoGraph could not transform <function train_preprocessing at 0x7f3cf43e8830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function train_preprocessing at 0x7f3cf43e8830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function data_aug at 0x7f3dc1872320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function data_aug at 0x7f3dc1872320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _fixup_shape at 0x7f3cf43e8950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _fixup_shape at 0x7f3cf43e8950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function validation_preprocessing at 0x7f3cf43e88c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function validation_preprocessing at 0x7f3cf43e88c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"UNET3D-L4-F32\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 40, 40, 40,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 40, 40, 40, 3 896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 40, 40, 40, 3 128         conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_14 (TensorFlow [(None, 40, 40, 40,  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 40, 40, 40, 3 27680       tf_op_layer_Relu_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 40, 40, 40, 3 128         conv3d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_15 (TensorFlow [(None, 40, 40, 40,  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 20, 20, 20, 3 0           tf_op_layer_Relu_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 20, 20, 20, 6 55360       max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 20, 20, 20, 6 256         conv3d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_16 (TensorFlow [(None, 20, 20, 20,  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 20, 20, 20, 6 110656      tf_op_layer_Relu_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 20, 20, 20, 6 256         conv3d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_17 (TensorFlow [(None, 20, 20, 20,  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3D)  (None, 10, 10, 10, 6 0           tf_op_layer_Relu_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_19 (Conv3D)              (None, 10, 10, 10, 1 221312      max_pooling3d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 10, 10, 10, 1 512         conv3d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_18 (TensorFlow [(None, 10, 10, 10,  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_20 (Conv3D)              (None, 10, 10, 10, 1 442496      tf_op_layer_Relu_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 10, 10, 10, 1 512         conv3d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_19 (TensorFlow [(None, 10, 10, 10,  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3D)  (None, 5, 5, 5, 128) 0           tf_op_layer_Relu_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_21 (Conv3D)              (None, 5, 5, 5, 256) 884992      max_pooling3d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 5, 5, 5, 256) 1024        conv3d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_20 (TensorFlow [(None, 5, 5, 5, 256 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_22 (Conv3D)              (None, 5, 5, 5, 256) 1769728     tf_op_layer_Relu_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 5, 5, 5, 256) 1024        conv3d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_21 (TensorFlow [(None, 5, 5, 5, 256 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_3 (Conv3DTrans (None, 10, 10, 10, 1 884864      tf_op_layer_Relu_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 10, 10, 10, 2 0           conv3d_transpose_3[0][0]         \n",
      "                                                                 tf_op_layer_Relu_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_23 (Conv3D)              (None, 10, 10, 10, 1 884864      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 10, 10, 10, 1 512         conv3d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_22 (TensorFlow [(None, 10, 10, 10,  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_24 (Conv3D)              (None, 10, 10, 10, 1 442496      tf_op_layer_Relu_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 10, 10, 10, 1 512         conv3d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_23 (TensorFlow [(None, 10, 10, 10,  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_4 (Conv3DTrans (None, 20, 20, 20, 6 221248      tf_op_layer_Relu_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 20, 20, 20, 1 0           conv3d_transpose_4[0][0]         \n",
      "                                                                 tf_op_layer_Relu_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_25 (Conv3D)              (None, 20, 20, 20, 6 221248      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 20, 20, 20, 6 256         conv3d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_24 (TensorFlow [(None, 20, 20, 20,  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_26 (Conv3D)              (None, 20, 20, 20, 6 110656      tf_op_layer_Relu_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 20, 20, 20, 6 256         conv3d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_25 (TensorFlow [(None, 20, 20, 20,  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_5 (Conv3DTrans (None, 40, 40, 40, 3 55328       tf_op_layer_Relu_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 40, 40, 40, 6 0           conv3d_transpose_5[0][0]         \n",
      "                                                                 tf_op_layer_Relu_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_27 (Conv3D)              (None, 40, 40, 40, 3 55328       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 40, 40, 40, 3 128         conv3d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_26 (TensorFlow [(None, 40, 40, 40,  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_28 (Conv3D)              (None, 40, 40, 40, 3 27680       tf_op_layer_Relu_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 40, 40, 40, 3 128         conv3d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_27 (TensorFlow [(None, 40, 40, 40,  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 40, 40, 40, 3 0           tf_op_layer_Relu_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_29 (Conv3D)              (None, 40, 40, 40, 1 33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,422,497\n",
      "Trainable params: 6,419,681\n",
      "Non-trainable params: 2,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f3bdc0f93b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f3bdc0f93b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 2/10 [=====>........................] - ETA: 2s - loss: 0.1511 - accuracy: 0.6585WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.201914). Check your callbacks.\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.8410WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f3bc42c9b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f3bc42c9b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.0863 - accuracy: 0.8410 - val_loss: 0.4265 - val_accuracy: 0.1400\n",
      "Epoch 2/2000\n",
      "10/10 [==============================] - 1s 135ms/step - loss: 0.0441 - accuracy: 0.9268 - val_loss: 0.4325 - val_accuracy: 0.1346\n",
      "Epoch 3/2000\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 0.0304 - accuracy: 0.9493 - val_loss: 0.3974 - val_accuracy: 0.2041\n",
      "Epoch 4/2000\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 0.0265 - accuracy: 0.9530 - val_loss: 0.3570 - val_accuracy: 0.2916\n",
      "Epoch 5/2000\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0229 - accuracy: 0.9573 - val_loss: 0.2177 - val_accuracy: 0.5889\n",
      "Epoch 6/2000\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 0.0195 - accuracy: 0.9637 - val_loss: 0.1688 - val_accuracy: 0.6323\n",
      "Epoch 7/2000\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0200 - accuracy: 0.9600 - val_loss: 0.1488 - val_accuracy: 0.6684\n",
      "Epoch 8/2000\n",
      "10/10 [==============================] - 1s 135ms/step - loss: 0.0191 - accuracy: 0.9613 - val_loss: 0.1162 - val_accuracy: 0.7549\n",
      "Epoch 9/2000\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0164 - accuracy: 0.9662 - val_loss: 0.0824 - val_accuracy: 0.8628\n",
      "Epoch 10/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0140 - accuracy: 0.9718 - val_loss: 0.0975 - val_accuracy: 0.8342\n",
      "Epoch 11/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0121 - accuracy: 0.9754 - val_loss: 0.0691 - val_accuracy: 0.8666\n",
      "Epoch 12/2000\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0118 - accuracy: 0.9759 - val_loss: 0.0664 - val_accuracy: 0.8666\n",
      "Epoch 13/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0108 - accuracy: 0.9775 - val_loss: 0.0640 - val_accuracy: 0.8666\n",
      "Epoch 14/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0108 - accuracy: 0.9775 - val_loss: 0.0651 - val_accuracy: 0.8666\n",
      "Epoch 15/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0111 - accuracy: 0.9765 - val_loss: 0.0633 - val_accuracy: 0.8666\n",
      "Epoch 16/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0103 - accuracy: 0.9781 - val_loss: 0.0638 - val_accuracy: 0.8666\n",
      "Epoch 17/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0107 - accuracy: 0.9763 - val_loss: 0.0631 - val_accuracy: 0.8666\n",
      "Epoch 18/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0102 - accuracy: 0.9779 - val_loss: 0.0635 - val_accuracy: 0.8666\n",
      "Epoch 19/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0101 - accuracy: 0.9777 - val_loss: 0.0629 - val_accuracy: 0.8666\n",
      "Epoch 20/2000\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0095 - accuracy: 0.9796 - val_loss: 0.0630 - val_accuracy: 0.8666\n",
      "Epoch 21/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0088 - accuracy: 0.9806 - val_loss: 0.0625 - val_accuracy: 0.8666\n",
      "Epoch 22/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0086 - accuracy: 0.9808 - val_loss: 0.0623 - val_accuracy: 0.8666\n",
      "Epoch 23/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0089 - accuracy: 0.9804 - val_loss: 0.0625 - val_accuracy: 0.8666\n",
      "Epoch 24/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0090 - accuracy: 0.9798 - val_loss: 0.0625 - val_accuracy: 0.8666\n",
      "Epoch 25/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0082 - accuracy: 0.9818 - val_loss: 0.0627 - val_accuracy: 0.8666\n",
      "Epoch 26/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0078 - accuracy: 0.9822 - val_loss: 0.0627 - val_accuracy: 0.8666\n",
      "Epoch 27/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0077 - accuracy: 0.9827 - val_loss: 0.0631 - val_accuracy: 0.8666\n",
      "Epoch 28/2000\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0074 - accuracy: 0.9834 - val_loss: 0.0633 - val_accuracy: 0.8666\n",
      "Epoch 29/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0078 - accuracy: 0.9822 - val_loss: 0.0631 - val_accuracy: 0.8666\n",
      "Epoch 30/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0077 - accuracy: 0.9827 - val_loss: 0.0635 - val_accuracy: 0.8666\n",
      "Epoch 31/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0073 - accuracy: 0.9833 - val_loss: 0.0632 - val_accuracy: 0.8666\n",
      "Epoch 32/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0071 - accuracy: 0.9838 - val_loss: 0.0636 - val_accuracy: 0.8666\n",
      "Epoch 33/2000\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0068 - accuracy: 0.9842 - val_loss: 0.0635 - val_accuracy: 0.8666\n",
      "Epoch 34/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0073 - accuracy: 0.9835 - val_loss: 0.0640 - val_accuracy: 0.8666\n",
      "Epoch 35/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0070 - accuracy: 0.9837 - val_loss: 0.0628 - val_accuracy: 0.8666\n",
      "Epoch 36/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0072 - accuracy: 0.9836 - val_loss: 0.0620 - val_accuracy: 0.8667\n",
      "Epoch 37/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0070 - accuracy: 0.9836 - val_loss: 0.0629 - val_accuracy: 0.8666\n",
      "Epoch 38/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0064 - accuracy: 0.9853 - val_loss: 0.0623 - val_accuracy: 0.8667\n",
      "Epoch 39/2000\n",
      "10/10 [==============================] - 2s 156ms/step - loss: 0.0064 - accuracy: 0.9851 - val_loss: 0.0625 - val_accuracy: 0.8666\n",
      "Epoch 40/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0062 - accuracy: 0.9856 - val_loss: 0.0624 - val_accuracy: 0.8667\n",
      "Epoch 41/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0063 - accuracy: 0.9851 - val_loss: 0.0608 - val_accuracy: 0.8676\n",
      "Epoch 42/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0062 - accuracy: 0.9856 - val_loss: 0.0573 - val_accuracy: 0.8714\n",
      "Epoch 43/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0061 - accuracy: 0.9857 - val_loss: 0.0534 - val_accuracy: 0.8778\n",
      "Epoch 44/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0062 - accuracy: 0.9856 - val_loss: 0.0568 - val_accuracy: 0.8740\n",
      "Epoch 45/2000\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0064 - accuracy: 0.9848 - val_loss: 0.0488 - val_accuracy: 0.8867\n",
      "Epoch 46/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0065 - accuracy: 0.9849 - val_loss: 0.0532 - val_accuracy: 0.8778\n",
      "Epoch 47/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0064 - accuracy: 0.9849 - val_loss: 0.0293 - val_accuracy: 0.9262\n",
      "Epoch 48/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0068 - accuracy: 0.9841 - val_loss: 0.0308 - val_accuracy: 0.9245\n",
      "Epoch 49/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0065 - accuracy: 0.9845 - val_loss: 0.0243 - val_accuracy: 0.9384\n",
      "Epoch 50/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0064 - accuracy: 0.9851 - val_loss: 0.0299 - val_accuracy: 0.9257\n",
      "Epoch 51/2000\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 0.0067 - accuracy: 0.9842 - val_loss: 0.0251 - val_accuracy: 0.9371\n",
      "Epoch 52/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0063 - accuracy: 0.9852 - val_loss: 0.0325 - val_accuracy: 0.9197\n",
      "Epoch 53/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0062 - accuracy: 0.9851 - val_loss: 0.0211 - val_accuracy: 0.9467\n",
      "Epoch 54/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0060 - accuracy: 0.9859 - val_loss: 0.0212 - val_accuracy: 0.9477\n",
      "Epoch 55/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0060 - accuracy: 0.9858 - val_loss: 0.0288 - val_accuracy: 0.9303\n",
      "Epoch 56/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0057 - accuracy: 0.9865 - val_loss: 0.0196 - val_accuracy: 0.9510\n",
      "Epoch 57/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0058 - accuracy: 0.9862 - val_loss: 0.0204 - val_accuracy: 0.9497\n",
      "Epoch 58/2000\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.0055 - accuracy: 0.9870 - val_loss: 0.0230 - val_accuracy: 0.9432\n",
      "Epoch 59/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0054 - accuracy: 0.9872 - val_loss: 0.0274 - val_accuracy: 0.9323\n",
      "Epoch 60/2000\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0053 - accuracy: 0.9874 - val_loss: 0.0216 - val_accuracy: 0.9461\n",
      "Epoch 61/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0053 - accuracy: 0.9873 - val_loss: 0.0234 - val_accuracy: 0.9424\n",
      "Epoch 62/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0054 - accuracy: 0.9871 - val_loss: 0.0205 - val_accuracy: 0.9496\n",
      "Epoch 63/2000\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0056 - accuracy: 0.9867 - val_loss: 0.0190 - val_accuracy: 0.9535\n",
      "Epoch 64/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0056 - accuracy: 0.9866 - val_loss: 0.0181 - val_accuracy: 0.9558\n",
      "Epoch 65/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0056 - accuracy: 0.9865 - val_loss: 0.0151 - val_accuracy: 0.9628\n",
      "Epoch 66/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0057 - accuracy: 0.9864 - val_loss: 0.0134 - val_accuracy: 0.9683\n",
      "Epoch 67/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0059 - accuracy: 0.9861 - val_loss: 0.0232 - val_accuracy: 0.9438\n",
      "Epoch 68/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0060 - accuracy: 0.9857 - val_loss: 0.0140 - val_accuracy: 0.9664\n",
      "Epoch 69/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0061 - accuracy: 0.9854 - val_loss: 0.0146 - val_accuracy: 0.9650\n",
      "Epoch 70/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0059 - accuracy: 0.9858 - val_loss: 0.0132 - val_accuracy: 0.9688\n",
      "Epoch 71/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0054 - accuracy: 0.9871 - val_loss: 0.0162 - val_accuracy: 0.9611\n",
      "Epoch 72/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0052 - accuracy: 0.9878 - val_loss: 0.0185 - val_accuracy: 0.9552\n",
      "Epoch 73/2000\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.0052 - accuracy: 0.9876 - val_loss: 0.0143 - val_accuracy: 0.9655\n",
      "Epoch 74/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0051 - accuracy: 0.9879 - val_loss: 0.0157 - val_accuracy: 0.9622\n",
      "Epoch 75/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0052 - accuracy: 0.9876 - val_loss: 0.0144 - val_accuracy: 0.9652\n",
      "Epoch 76/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0050 - accuracy: 0.9881 - val_loss: 0.0138 - val_accuracy: 0.9668\n",
      "Epoch 77/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0052 - accuracy: 0.9878 - val_loss: 0.0172 - val_accuracy: 0.9589\n",
      "Epoch 78/2000\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0050 - accuracy: 0.9880 - val_loss: 0.0164 - val_accuracy: 0.9605\n",
      "Epoch 79/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0052 - accuracy: 0.9875 - val_loss: 0.0136 - val_accuracy: 0.9678\n",
      "Epoch 80/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0051 - accuracy: 0.9878 - val_loss: 0.0159 - val_accuracy: 0.9616\n",
      "Epoch 81/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0052 - accuracy: 0.9874 - val_loss: 0.0132 - val_accuracy: 0.9695\n",
      "Epoch 82/2000\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0058 - accuracy: 0.9861 - val_loss: 0.0175 - val_accuracy: 0.9581\n",
      "Epoch 83/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0055 - accuracy: 0.9867 - val_loss: 0.0130 - val_accuracy: 0.9692\n",
      "Epoch 84/2000\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.0052 - accuracy: 0.9873 - val_loss: 0.0132 - val_accuracy: 0.9693\n",
      "Epoch 85/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0051 - accuracy: 0.9876 - val_loss: 0.0132 - val_accuracy: 0.9687\n",
      "Epoch 86/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0048 - accuracy: 0.9885 - val_loss: 0.0149 - val_accuracy: 0.9645\n",
      "Epoch 87/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0047 - accuracy: 0.9888 - val_loss: 0.0144 - val_accuracy: 0.9660\n",
      "Epoch 88/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0048 - accuracy: 0.9883 - val_loss: 0.0133 - val_accuracy: 0.9697\n",
      "Epoch 89/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0049 - accuracy: 0.9883 - val_loss: 0.0151 - val_accuracy: 0.9643\n",
      "Epoch 90/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0049 - accuracy: 0.9884 - val_loss: 0.0140 - val_accuracy: 0.9669\n",
      "Epoch 91/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0047 - accuracy: 0.9885 - val_loss: 0.0136 - val_accuracy: 0.9677\n",
      "Epoch 92/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0048 - accuracy: 0.9884 - val_loss: 0.0140 - val_accuracy: 0.9672\n",
      "Epoch 93/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0047 - accuracy: 0.9888 - val_loss: 0.0147 - val_accuracy: 0.9650\n",
      "Epoch 94/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0047 - accuracy: 0.9887 - val_loss: 0.0143 - val_accuracy: 0.9665\n",
      "Epoch 95/2000\n",
      "10/10 [==============================] - 2s 155ms/step - loss: 0.0045 - accuracy: 0.9891 - val_loss: 0.0137 - val_accuracy: 0.9675\n",
      "Epoch 96/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0046 - accuracy: 0.9888 - val_loss: 0.0130 - val_accuracy: 0.9700\n",
      "Epoch 97/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0047 - accuracy: 0.9889 - val_loss: 0.0171 - val_accuracy: 0.9591\n",
      "Epoch 98/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0048 - accuracy: 0.9884 - val_loss: 0.0135 - val_accuracy: 0.9686\n",
      "Epoch 99/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0049 - accuracy: 0.9880 - val_loss: 0.0149 - val_accuracy: 0.9650\n",
      "Epoch 100/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0048 - accuracy: 0.9884 - val_loss: 0.0144 - val_accuracy: 0.9661\n",
      "Epoch 101/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0051 - accuracy: 0.9879 - val_loss: 0.0156 - val_accuracy: 0.9632\n",
      "Epoch 102/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0049 - accuracy: 0.9881 - val_loss: 0.0142 - val_accuracy: 0.9676\n",
      "Epoch 103/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0048 - accuracy: 0.9885 - val_loss: 0.0134 - val_accuracy: 0.9691\n",
      "Epoch 104/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0046 - accuracy: 0.9891 - val_loss: 0.0165 - val_accuracy: 0.9612\n",
      "Epoch 105/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0045 - accuracy: 0.9890 - val_loss: 0.0136 - val_accuracy: 0.9680\n",
      "Epoch 106/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0045 - accuracy: 0.9893 - val_loss: 0.0141 - val_accuracy: 0.9669\n",
      "Epoch 107/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0045 - accuracy: 0.9892 - val_loss: 0.0164 - val_accuracy: 0.9611\n",
      "Epoch 108/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0043 - accuracy: 0.9894 - val_loss: 0.0135 - val_accuracy: 0.9685\n",
      "Epoch 109/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0044 - accuracy: 0.9894 - val_loss: 0.0151 - val_accuracy: 0.9645\n",
      "Epoch 110/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0043 - accuracy: 0.9896 - val_loss: 0.0146 - val_accuracy: 0.9655\n",
      "Epoch 111/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0042 - accuracy: 0.9898 - val_loss: 0.0148 - val_accuracy: 0.9652\n",
      "Epoch 112/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0042 - accuracy: 0.9898 - val_loss: 0.0143 - val_accuracy: 0.9663\n",
      "Epoch 113/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0040 - accuracy: 0.9903 - val_loss: 0.0141 - val_accuracy: 0.9669\n",
      "Epoch 114/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0041 - accuracy: 0.9902 - val_loss: 0.0152 - val_accuracy: 0.9644\n",
      "Epoch 115/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0041 - accuracy: 0.9900 - val_loss: 0.0134 - val_accuracy: 0.9686\n",
      "Epoch 116/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0040 - accuracy: 0.9904 - val_loss: 0.0143 - val_accuracy: 0.9664\n",
      "Epoch 117/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0041 - accuracy: 0.9901 - val_loss: 0.0151 - val_accuracy: 0.9646\n",
      "Epoch 118/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0043 - accuracy: 0.9897 - val_loss: 0.0148 - val_accuracy: 0.9652\n",
      "Epoch 119/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0044 - accuracy: 0.9893 - val_loss: 0.0150 - val_accuracy: 0.9648\n",
      "Epoch 120/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0043 - accuracy: 0.9897 - val_loss: 0.0152 - val_accuracy: 0.9639\n",
      "Epoch 121/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0040 - accuracy: 0.9903 - val_loss: 0.0135 - val_accuracy: 0.9685\n",
      "Epoch 122/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0041 - accuracy: 0.9900 - val_loss: 0.0145 - val_accuracy: 0.9664\n",
      "Epoch 123/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0041 - accuracy: 0.9903 - val_loss: 0.0145 - val_accuracy: 0.9660\n",
      "Epoch 124/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0040 - accuracy: 0.9904 - val_loss: 0.0141 - val_accuracy: 0.9670\n",
      "Epoch 125/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0040 - accuracy: 0.9903 - val_loss: 0.0139 - val_accuracy: 0.9679\n",
      "Epoch 126/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0041 - accuracy: 0.9902 - val_loss: 0.0145 - val_accuracy: 0.9661\n",
      "Epoch 127/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0041 - accuracy: 0.9903 - val_loss: 0.0147 - val_accuracy: 0.9656\n",
      "Epoch 128/2000\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.0041 - accuracy: 0.9900 - val_loss: 0.0132 - val_accuracy: 0.9699\n",
      "Epoch 129/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0043 - accuracy: 0.9898 - val_loss: 0.0148 - val_accuracy: 0.9655\n",
      "Epoch 130/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0043 - accuracy: 0.9896 - val_loss: 0.0132 - val_accuracy: 0.9694\n",
      "Epoch 131/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0042 - accuracy: 0.9897 - val_loss: 0.0143 - val_accuracy: 0.9670\n",
      "Epoch 132/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0042 - accuracy: 0.9898 - val_loss: 0.0138 - val_accuracy: 0.9678\n",
      "Epoch 133/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0041 - accuracy: 0.9903 - val_loss: 0.0143 - val_accuracy: 0.9667\n",
      "Epoch 134/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0039 - accuracy: 0.9904 - val_loss: 0.0142 - val_accuracy: 0.9671\n",
      "Epoch 135/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0038 - accuracy: 0.9907 - val_loss: 0.0136 - val_accuracy: 0.9689\n",
      "Epoch 136/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0039 - accuracy: 0.9908 - val_loss: 0.0151 - val_accuracy: 0.9651\n",
      "Epoch 137/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0040 - accuracy: 0.9902 - val_loss: 0.0134 - val_accuracy: 0.9692\n",
      "Epoch 138/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0039 - accuracy: 0.9904 - val_loss: 0.0133 - val_accuracy: 0.9693\n",
      "Epoch 139/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0037 - accuracy: 0.9911 - val_loss: 0.0147 - val_accuracy: 0.9659\n",
      "Epoch 140/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0036 - accuracy: 0.9913 - val_loss: 0.0143 - val_accuracy: 0.9669\n",
      "Epoch 141/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0035 - accuracy: 0.9915 - val_loss: 0.0148 - val_accuracy: 0.9655\n",
      "Epoch 142/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0036 - accuracy: 0.9911 - val_loss: 0.0136 - val_accuracy: 0.9688\n",
      "Epoch 143/2000\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0036 - accuracy: 0.9914 - val_loss: 0.0151 - val_accuracy: 0.9650\n",
      "Epoch 144/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0036 - accuracy: 0.9914 - val_loss: 0.0145 - val_accuracy: 0.9664\n",
      "Epoch 145/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0036 - accuracy: 0.9913 - val_loss: 0.0138 - val_accuracy: 0.9683\n",
      "Epoch 146/2000\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.0035 - accuracy: 0.9917 - val_loss: 0.0145 - val_accuracy: 0.9662\n",
      "Epoch 147/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0035 - accuracy: 0.9916 - val_loss: 0.0144 - val_accuracy: 0.9666\n",
      "Epoch 148/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0034 - accuracy: 0.9919 - val_loss: 0.0147 - val_accuracy: 0.9659\n",
      "Epoch 149/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0034 - accuracy: 0.9919 - val_loss: 0.0149 - val_accuracy: 0.9652\n",
      "Epoch 150/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0034 - accuracy: 0.9917 - val_loss: 0.0148 - val_accuracy: 0.9657\n",
      "Epoch 151/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0033 - accuracy: 0.9922 - val_loss: 0.0142 - val_accuracy: 0.9671\n",
      "Epoch 152/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0034 - accuracy: 0.9919 - val_loss: 0.0142 - val_accuracy: 0.9675\n",
      "Epoch 153/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0034 - accuracy: 0.9920 - val_loss: 0.0150 - val_accuracy: 0.9653\n",
      "Epoch 154/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0032 - accuracy: 0.9923 - val_loss: 0.0143 - val_accuracy: 0.9669\n",
      "Epoch 155/2000\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0032 - accuracy: 0.9924 - val_loss: 0.0144 - val_accuracy: 0.9668\n",
      "Epoch 156/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0033 - accuracy: 0.9919 - val_loss: 0.0141 - val_accuracy: 0.9678\n",
      "Epoch 157/2000\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.0034 - accuracy: 0.9920 - val_loss: 0.0154 - val_accuracy: 0.9646\n",
      "Epoch 158/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0035 - accuracy: 0.9917 - val_loss: 0.0146 - val_accuracy: 0.9663\n",
      "Epoch 159/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0033 - accuracy: 0.9918 - val_loss: 0.0134 - val_accuracy: 0.9693\n",
      "Epoch 160/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0034 - accuracy: 0.9919 - val_loss: 0.0149 - val_accuracy: 0.9658\n",
      "Epoch 161/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0033 - accuracy: 0.9922 - val_loss: 0.0144 - val_accuracy: 0.9668\n",
      "Epoch 162/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0032 - accuracy: 0.9921 - val_loss: 0.0139 - val_accuracy: 0.9684\n",
      "Epoch 163/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0031 - accuracy: 0.9927 - val_loss: 0.0142 - val_accuracy: 0.9672\n",
      "Epoch 164/2000\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0031 - accuracy: 0.9927 - val_loss: 0.0142 - val_accuracy: 0.9674\n",
      "Epoch 165/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0030 - accuracy: 0.9928 - val_loss: 0.0146 - val_accuracy: 0.9663\n",
      "Epoch 166/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0030 - accuracy: 0.9931 - val_loss: 0.0145 - val_accuracy: 0.9666\n",
      "Epoch 167/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0029 - accuracy: 0.9931 - val_loss: 0.0149 - val_accuracy: 0.9657\n",
      "Epoch 168/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0031 - accuracy: 0.9926 - val_loss: 0.0140 - val_accuracy: 0.9679\n",
      "Epoch 169/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0031 - accuracy: 0.9926 - val_loss: 0.0150 - val_accuracy: 0.9655\n",
      "Epoch 170/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0031 - accuracy: 0.9926 - val_loss: 0.0151 - val_accuracy: 0.9652\n",
      "Epoch 171/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0031 - accuracy: 0.9925 - val_loss: 0.0141 - val_accuracy: 0.9679\n",
      "Epoch 172/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0031 - accuracy: 0.9926 - val_loss: 0.0149 - val_accuracy: 0.9658\n",
      "Epoch 173/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0030 - accuracy: 0.9930 - val_loss: 0.0149 - val_accuracy: 0.9657\n",
      "Epoch 174/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0030 - accuracy: 0.9928 - val_loss: 0.0145 - val_accuracy: 0.9667\n",
      "Epoch 175/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0030 - accuracy: 0.9928 - val_loss: 0.0136 - val_accuracy: 0.9691\n",
      "Epoch 176/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0030 - accuracy: 0.9930 - val_loss: 0.0153 - val_accuracy: 0.9650\n",
      "Epoch 177/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0029 - accuracy: 0.9930 - val_loss: 0.0145 - val_accuracy: 0.9668\n",
      "Epoch 178/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0030 - accuracy: 0.9929 - val_loss: 0.0148 - val_accuracy: 0.9660\n",
      "Epoch 179/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0029 - accuracy: 0.9931 - val_loss: 0.0142 - val_accuracy: 0.9675\n",
      "Epoch 180/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0029 - accuracy: 0.9929 - val_loss: 0.0147 - val_accuracy: 0.9665\n",
      "Epoch 181/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0029 - accuracy: 0.9931 - val_loss: 0.0149 - val_accuracy: 0.9657\n",
      "Epoch 182/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0029 - accuracy: 0.9929 - val_loss: 0.0141 - val_accuracy: 0.9679\n",
      "Epoch 183/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0028 - accuracy: 0.9934 - val_loss: 0.0144 - val_accuracy: 0.9672\n",
      "Epoch 184/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0028 - accuracy: 0.9935 - val_loss: 0.0145 - val_accuracy: 0.9671\n",
      "Epoch 185/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0027 - accuracy: 0.9936 - val_loss: 0.0147 - val_accuracy: 0.9663\n",
      "Epoch 186/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0027 - accuracy: 0.9935 - val_loss: 0.0141 - val_accuracy: 0.9680\n",
      "Epoch 187/2000\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0027 - accuracy: 0.9936 - val_loss: 0.0146 - val_accuracy: 0.9670\n",
      "Epoch 188/2000\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.0026 - accuracy: 0.9938 - val_loss: 0.0148 - val_accuracy: 0.9663\n",
      "Epoch 189/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0026 - accuracy: 0.9939 - val_loss: 0.0145 - val_accuracy: 0.9669\n",
      "Epoch 190/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0026 - accuracy: 0.9939 - val_loss: 0.0144 - val_accuracy: 0.9672\n",
      "Epoch 191/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0027 - accuracy: 0.9938 - val_loss: 0.0146 - val_accuracy: 0.9667\n",
      "Epoch 192/2000\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.0026 - accuracy: 0.9940 - val_loss: 0.0151 - val_accuracy: 0.9655\n",
      "Epoch 193/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0026 - accuracy: 0.9938 - val_loss: 0.0147 - val_accuracy: 0.9667\n",
      "Epoch 194/2000\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0026 - accuracy: 0.9937 - val_loss: 0.0146 - val_accuracy: 0.9669\n",
      "Epoch 195/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0026 - accuracy: 0.9940 - val_loss: 0.0151 - val_accuracy: 0.9654\n",
      "Epoch 196/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0026 - accuracy: 0.9939 - val_loss: 0.0147 - val_accuracy: 0.9664\n",
      "Epoch 197/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0026 - accuracy: 0.9937 - val_loss: 0.0139 - val_accuracy: 0.9686\n",
      "Epoch 198/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0027 - accuracy: 0.9937 - val_loss: 0.0146 - val_accuracy: 0.9668\n",
      "Epoch 199/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0026 - accuracy: 0.9941 - val_loss: 0.0151 - val_accuracy: 0.9657\n",
      "Epoch 200/2000\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0026 - accuracy: 0.9938 - val_loss: 0.0140 - val_accuracy: 0.9683\n",
      "Epoch 201/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0026 - accuracy: 0.9938 - val_loss: 0.0144 - val_accuracy: 0.9676\n",
      "Epoch 202/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0025 - accuracy: 0.9943 - val_loss: 0.0149 - val_accuracy: 0.9662\n",
      "Epoch 203/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0025 - accuracy: 0.9941 - val_loss: 0.0144 - val_accuracy: 0.9673\n",
      "Epoch 204/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0024 - accuracy: 0.9943 - val_loss: 0.0144 - val_accuracy: 0.9674\n",
      "Epoch 205/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0024 - accuracy: 0.9944 - val_loss: 0.0150 - val_accuracy: 0.9659\n",
      "Epoch 206/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0024 - accuracy: 0.9944 - val_loss: 0.0147 - val_accuracy: 0.9668\n",
      "Epoch 207/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0024 - accuracy: 0.9945 - val_loss: 0.0148 - val_accuracy: 0.9666\n",
      "Epoch 208/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0024 - accuracy: 0.9946 - val_loss: 0.0146 - val_accuracy: 0.9669\n",
      "Epoch 209/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0025 - accuracy: 0.9942 - val_loss: 0.0145 - val_accuracy: 0.9673\n",
      "Epoch 210/2000\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0024 - accuracy: 0.9945 - val_loss: 0.0149 - val_accuracy: 0.9662\n",
      "Epoch 211/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0024 - accuracy: 0.9944 - val_loss: 0.0145 - val_accuracy: 0.9674\n",
      "Epoch 212/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0024 - accuracy: 0.9944 - val_loss: 0.0144 - val_accuracy: 0.9676\n",
      "Epoch 213/2000\n",
      "10/10 [==============================] - 2s 157ms/step - loss: 0.0023 - accuracy: 0.9946 - val_loss: 0.0148 - val_accuracy: 0.9667\n",
      "Epoch 214/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0023 - accuracy: 0.9947 - val_loss: 0.0145 - val_accuracy: 0.9674\n",
      "Epoch 215/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0023 - accuracy: 0.9946 - val_loss: 0.0147 - val_accuracy: 0.9668\n",
      "Epoch 216/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0023 - accuracy: 0.9946 - val_loss: 0.0145 - val_accuracy: 0.9674\n",
      "Epoch 217/2000\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0024 - accuracy: 0.9945 - val_loss: 0.0148 - val_accuracy: 0.9666\n",
      "Epoch 218/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0024 - accuracy: 0.9944 - val_loss: 0.0143 - val_accuracy: 0.9678\n",
      "Epoch 219/2000\n",
      "10/10 [==============================] - 2s 155ms/step - loss: 0.0024 - accuracy: 0.9945 - val_loss: 0.0151 - val_accuracy: 0.9660\n",
      "Epoch 220/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0024 - accuracy: 0.9943 - val_loss: 0.0150 - val_accuracy: 0.9662\n",
      "Epoch 221/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0024 - accuracy: 0.9944 - val_loss: 0.0144 - val_accuracy: 0.9676\n",
      "Epoch 222/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0024 - accuracy: 0.9945 - val_loss: 0.0146 - val_accuracy: 0.9671\n",
      "Epoch 223/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0023 - accuracy: 0.9946 - val_loss: 0.0152 - val_accuracy: 0.9659\n",
      "Epoch 224/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0024 - accuracy: 0.9945 - val_loss: 0.0149 - val_accuracy: 0.9664\n",
      "Epoch 225/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0023 - accuracy: 0.9945 - val_loss: 0.0141 - val_accuracy: 0.9683\n",
      "Epoch 226/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0023 - accuracy: 0.9947 - val_loss: 0.0147 - val_accuracy: 0.9672\n",
      "Epoch 227/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0023 - accuracy: 0.9948 - val_loss: 0.0147 - val_accuracy: 0.9670\n",
      "Epoch 228/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0022 - accuracy: 0.9948 - val_loss: 0.0147 - val_accuracy: 0.9669\n",
      "Epoch 229/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0022 - accuracy: 0.9951 - val_loss: 0.0146 - val_accuracy: 0.9672\n",
      "Epoch 230/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0021 - accuracy: 0.9951 - val_loss: 0.0147 - val_accuracy: 0.9671\n",
      "Epoch 231/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0021 - accuracy: 0.9951 - val_loss: 0.0146 - val_accuracy: 0.9673\n",
      "Epoch 232/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0021 - accuracy: 0.9951 - val_loss: 0.0151 - val_accuracy: 0.9662\n",
      "Epoch 233/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0021 - accuracy: 0.9951 - val_loss: 0.0147 - val_accuracy: 0.9671\n",
      "Epoch 234/2000\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 0.0022 - accuracy: 0.9950 - val_loss: 0.0144 - val_accuracy: 0.9677\n",
      "Epoch 235/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0021 - accuracy: 0.9953 - val_loss: 0.0149 - val_accuracy: 0.9665\n",
      "Epoch 236/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0021 - accuracy: 0.9952 - val_loss: 0.0147 - val_accuracy: 0.9670\n",
      "Epoch 237/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0021 - accuracy: 0.9951 - val_loss: 0.0143 - val_accuracy: 0.9680\n",
      "Epoch 238/2000\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.0021 - accuracy: 0.9952 - val_loss: 0.0148 - val_accuracy: 0.9670\n",
      "Epoch 239/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0021 - accuracy: 0.9952 - val_loss: 0.0149 - val_accuracy: 0.9667\n",
      "Epoch 240/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0021 - accuracy: 0.9950 - val_loss: 0.0145 - val_accuracy: 0.9677\n",
      "Epoch 241/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0021 - accuracy: 0.9951 - val_loss: 0.0147 - val_accuracy: 0.9672\n",
      "Epoch 242/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0021 - accuracy: 0.9954 - val_loss: 0.0149 - val_accuracy: 0.9667\n",
      "Epoch 243/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0020 - accuracy: 0.9953 - val_loss: 0.0144 - val_accuracy: 0.9679\n",
      "Epoch 244/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0021 - accuracy: 0.9952 - val_loss: 0.0150 - val_accuracy: 0.9665\n",
      "Epoch 245/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0021 - accuracy: 0.9953 - val_loss: 0.0148 - val_accuracy: 0.9671\n",
      "Epoch 246/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0021 - accuracy: 0.9951 - val_loss: 0.0142 - val_accuracy: 0.9683\n",
      "Epoch 247/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0020 - accuracy: 0.9954 - val_loss: 0.0149 - val_accuracy: 0.9668\n",
      "Epoch 248/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0020 - accuracy: 0.9954 - val_loss: 0.0145 - val_accuracy: 0.9677\n",
      "Epoch 249/2000\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0021 - accuracy: 0.9953 - val_loss: 0.0147 - val_accuracy: 0.9672\n",
      "Epoch 250/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0020 - accuracy: 0.9954 - val_loss: 0.0147 - val_accuracy: 0.9672\n",
      "Epoch 251/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0020 - accuracy: 0.9953 - val_loss: 0.0143 - val_accuracy: 0.9681\n",
      "Epoch 252/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0021 - accuracy: 0.9952 - val_loss: 0.0146 - val_accuracy: 0.9676\n",
      "Epoch 253/2000\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.0020 - accuracy: 0.9954 - val_loss: 0.0147 - val_accuracy: 0.9674\n",
      "Epoch 254/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0020 - accuracy: 0.9955 - val_loss: 0.0145 - val_accuracy: 0.9677\n",
      "Epoch 255/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0020 - accuracy: 0.9955 - val_loss: 0.0146 - val_accuracy: 0.9676\n",
      "Epoch 256/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0020 - accuracy: 0.9954 - val_loss: 0.0146 - val_accuracy: 0.9674\n",
      "Epoch 257/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0019 - accuracy: 0.9957 - val_loss: 0.0146 - val_accuracy: 0.9676\n",
      "Epoch 258/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0019 - accuracy: 0.9956 - val_loss: 0.0146 - val_accuracy: 0.9677\n",
      "Epoch 259/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0019 - accuracy: 0.9956 - val_loss: 0.0146 - val_accuracy: 0.9676\n",
      "Epoch 260/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0019 - accuracy: 0.9957 - val_loss: 0.0148 - val_accuracy: 0.9672\n",
      "Epoch 261/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0019 - accuracy: 0.9957 - val_loss: 0.0147 - val_accuracy: 0.9674\n",
      "Epoch 262/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0019 - accuracy: 0.9959 - val_loss: 0.0147 - val_accuracy: 0.9673\n",
      "Epoch 263/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0019 - accuracy: 0.9958 - val_loss: 0.0148 - val_accuracy: 0.9670\n",
      "Epoch 264/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0019 - accuracy: 0.9956 - val_loss: 0.0145 - val_accuracy: 0.9679\n",
      "Epoch 265/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0019 - accuracy: 0.9957 - val_loss: 0.0146 - val_accuracy: 0.9676\n",
      "Epoch 266/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0019 - accuracy: 0.9957 - val_loss: 0.0146 - val_accuracy: 0.9676\n",
      "Epoch 267/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0019 - accuracy: 0.9958 - val_loss: 0.0145 - val_accuracy: 0.9679\n",
      "Epoch 268/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0019 - accuracy: 0.9958 - val_loss: 0.0147 - val_accuracy: 0.9673\n",
      "Epoch 269/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0018 - accuracy: 0.9960 - val_loss: 0.0147 - val_accuracy: 0.9674\n",
      "Epoch 270/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0018 - accuracy: 0.9958 - val_loss: 0.0145 - val_accuracy: 0.9679\n",
      "Epoch 271/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0018 - accuracy: 0.9958 - val_loss: 0.0144 - val_accuracy: 0.9680\n",
      "Epoch 272/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0019 - accuracy: 0.9959 - val_loss: 0.0151 - val_accuracy: 0.9666\n",
      "Epoch 273/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0019 - accuracy: 0.9957 - val_loss: 0.0145 - val_accuracy: 0.9677\n",
      "Epoch 274/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0019 - accuracy: 0.9957 - val_loss: 0.0145 - val_accuracy: 0.9679\n",
      "Epoch 275/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0019 - accuracy: 0.9959 - val_loss: 0.0150 - val_accuracy: 0.9669\n",
      "Epoch 276/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0019 - accuracy: 0.9958 - val_loss: 0.0145 - val_accuracy: 0.9679\n",
      "Epoch 277/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0019 - accuracy: 0.9957 - val_loss: 0.0144 - val_accuracy: 0.9683\n",
      "Epoch 278/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0018 - accuracy: 0.9960 - val_loss: 0.0149 - val_accuracy: 0.9671\n",
      "Epoch 279/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0018 - accuracy: 0.9959 - val_loss: 0.0145 - val_accuracy: 0.9680\n",
      "Epoch 280/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0018 - accuracy: 0.9960 - val_loss: 0.0145 - val_accuracy: 0.9678\n",
      "Epoch 281/2000\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0018 - accuracy: 0.9960 - val_loss: 0.0147 - val_accuracy: 0.9675\n",
      "Epoch 282/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0018 - accuracy: 0.9961 - val_loss: 0.0145 - val_accuracy: 0.9679\n",
      "Epoch 283/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0018 - accuracy: 0.9961 - val_loss: 0.0147 - val_accuracy: 0.9675\n",
      "Epoch 284/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0018 - accuracy: 0.9962 - val_loss: 0.0147 - val_accuracy: 0.9674\n",
      "Epoch 285/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0018 - accuracy: 0.9959 - val_loss: 0.0145 - val_accuracy: 0.9679\n",
      "Epoch 286/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0018 - accuracy: 0.9962 - val_loss: 0.0149 - val_accuracy: 0.9671\n",
      "Epoch 287/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0018 - accuracy: 0.9960 - val_loss: 0.0147 - val_accuracy: 0.9675\n",
      "Epoch 288/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0018 - accuracy: 0.9961 - val_loss: 0.0145 - val_accuracy: 0.9681\n",
      "Epoch 289/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0017 - accuracy: 0.9962 - val_loss: 0.0148 - val_accuracy: 0.9674\n",
      "Epoch 290/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0017 - accuracy: 0.9962 - val_loss: 0.0148 - val_accuracy: 0.9673\n",
      "Epoch 291/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0017 - accuracy: 0.9961 - val_loss: 0.0146 - val_accuracy: 0.9679\n",
      "Epoch 292/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0017 - accuracy: 0.9963 - val_loss: 0.0148 - val_accuracy: 0.9674\n",
      "Epoch 293/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0017 - accuracy: 0.9962 - val_loss: 0.0147 - val_accuracy: 0.9676\n",
      "Epoch 294/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0017 - accuracy: 0.9963 - val_loss: 0.0147 - val_accuracy: 0.9674\n",
      "Epoch 295/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0017 - accuracy: 0.9963 - val_loss: 0.0145 - val_accuracy: 0.9679\n",
      "Epoch 296/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0017 - accuracy: 0.9962 - val_loss: 0.0146 - val_accuracy: 0.9679\n",
      "Epoch 297/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0017 - accuracy: 0.9964 - val_loss: 0.0148 - val_accuracy: 0.9674\n",
      "Epoch 298/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0017 - accuracy: 0.9962 - val_loss: 0.0144 - val_accuracy: 0.9683\n",
      "Epoch 299/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0017 - accuracy: 0.9963 - val_loss: 0.0147 - val_accuracy: 0.9675\n",
      "Epoch 300/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0017 - accuracy: 0.9963 - val_loss: 0.0149 - val_accuracy: 0.9670\n",
      "Epoch 301/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0017 - accuracy: 0.9962 - val_loss: 0.0145 - val_accuracy: 0.9681\n",
      "Epoch 302/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0017 - accuracy: 0.9963 - val_loss: 0.0149 - val_accuracy: 0.9673\n",
      "Epoch 303/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0017 - accuracy: 0.9964 - val_loss: 0.0146 - val_accuracy: 0.9678\n",
      "Epoch 304/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0017 - accuracy: 0.9964 - val_loss: 0.0145 - val_accuracy: 0.9680\n",
      "Epoch 305/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0017 - accuracy: 0.9965 - val_loss: 0.0147 - val_accuracy: 0.9677\n",
      "Epoch 306/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0017 - accuracy: 0.9964 - val_loss: 0.0148 - val_accuracy: 0.9674\n",
      "Epoch 307/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0016 - accuracy: 0.9964 - val_loss: 0.0146 - val_accuracy: 0.9680\n",
      "Epoch 308/2000\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.0016 - accuracy: 0.9965 - val_loss: 0.0147 - val_accuracy: 0.9677\n",
      "Epoch 309/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0016 - accuracy: 0.9965 - val_loss: 0.0147 - val_accuracy: 0.9677\n",
      "Epoch 310/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0016 - accuracy: 0.9964 - val_loss: 0.0145 - val_accuracy: 0.9681\n",
      "Epoch 311/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0017 - accuracy: 0.9963 - val_loss: 0.0147 - val_accuracy: 0.9676\n",
      "Epoch 312/2000\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.0016 - accuracy: 0.9965 - val_loss: 0.0146 - val_accuracy: 0.9680\n",
      "Epoch 313/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0016 - accuracy: 0.9965 - val_loss: 0.0147 - val_accuracy: 0.9676\n",
      "Epoch 314/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0017 - accuracy: 0.9964 - val_loss: 0.0146 - val_accuracy: 0.9679\n",
      "Epoch 315/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0016 - accuracy: 0.9964 - val_loss: 0.0147 - val_accuracy: 0.9676\n",
      "Epoch 316/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0016 - accuracy: 0.9965 - val_loss: 0.0146 - val_accuracy: 0.9679\n",
      "Epoch 317/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0016 - accuracy: 0.9964 - val_loss: 0.0147 - val_accuracy: 0.9679\n",
      "Epoch 318/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.0147 - val_accuracy: 0.9677\n",
      "Epoch 319/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0016 - accuracy: 0.9965 - val_loss: 0.0145 - val_accuracy: 0.9682\n",
      "Epoch 320/2000\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.0016 - accuracy: 0.9964 - val_loss: 0.0147 - val_accuracy: 0.9679\n",
      "Epoch 321/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.0146 - val_accuracy: 0.9681\n",
      "Epoch 322/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0016 - accuracy: 0.9965 - val_loss: 0.0147 - val_accuracy: 0.9679\n",
      "Epoch 323/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0016 - accuracy: 0.9965 - val_loss: 0.0148 - val_accuracy: 0.9674\n",
      "Epoch 324/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0016 - accuracy: 0.9965 - val_loss: 0.0147 - val_accuracy: 0.9679\n",
      "Epoch 325/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.0147 - val_accuracy: 0.9678\n",
      "Epoch 326/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.0147 - val_accuracy: 0.9679\n",
      "Epoch 327/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.0147 - val_accuracy: 0.9678\n",
      "Epoch 328/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.0146 - val_accuracy: 0.9680\n",
      "Epoch 329/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.0147 - val_accuracy: 0.9677\n",
      "Epoch 330/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.0146 - val_accuracy: 0.9681\n",
      "Epoch 331/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.0147 - val_accuracy: 0.9678\n",
      "Epoch 332/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0015 - accuracy: 0.9967 - val_loss: 0.0147 - val_accuracy: 0.9678\n",
      "Epoch 333/2000\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.0147 - val_accuracy: 0.9678\n",
      "Epoch 334/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.0147 - val_accuracy: 0.9678\n",
      "Epoch 335/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.0147 - val_accuracy: 0.9678\n",
      "Epoch 336/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0015 - accuracy: 0.9967 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 337/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.0147 - val_accuracy: 0.9679\n",
      "Epoch 338/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.0147 - val_accuracy: 0.9678\n",
      "Epoch 339/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.0147 - val_accuracy: 0.9678\n",
      "Epoch 340/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0015 - accuracy: 0.9967 - val_loss: 0.0147 - val_accuracy: 0.9678\n",
      "Epoch 341/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0015 - accuracy: 0.9968 - val_loss: 0.0147 - val_accuracy: 0.9679\n",
      "Epoch 342/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0015 - accuracy: 0.9967 - val_loss: 0.0146 - val_accuracy: 0.9681\n",
      "Epoch 343/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0015 - accuracy: 0.9967 - val_loss: 0.0146 - val_accuracy: 0.9680\n",
      "Epoch 344/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0015 - accuracy: 0.9968 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 345/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0015 - accuracy: 0.9967 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 346/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0016 - accuracy: 0.9966 - val_loss: 0.0148 - val_accuracy: 0.9678\n",
      "Epoch 347/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0015 - accuracy: 0.9967 - val_loss: 0.0146 - val_accuracy: 0.9681\n",
      "Epoch 348/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0015 - accuracy: 0.9968 - val_loss: 0.0148 - val_accuracy: 0.9678\n",
      "Epoch 349/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0015 - accuracy: 0.9967 - val_loss: 0.0146 - val_accuracy: 0.9681\n",
      "Epoch 350/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0015 - accuracy: 0.9968 - val_loss: 0.0146 - val_accuracy: 0.9680\n",
      "Epoch 351/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0015 - accuracy: 0.9968 - val_loss: 0.0146 - val_accuracy: 0.9681\n",
      "Epoch 352/2000\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 353/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0015 - accuracy: 0.9967 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 354/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 355/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0015 - accuracy: 0.9968 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 356/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 357/2000\n",
      "10/10 [==============================] - 2s 155ms/step - loss: 0.0015 - accuracy: 0.9968 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 358/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0015 - accuracy: 0.9967 - val_loss: 0.0147 - val_accuracy: 0.9679\n",
      "Epoch 359/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 360/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0015 - accuracy: 0.9968 - val_loss: 0.0148 - val_accuracy: 0.9678\n",
      "Epoch 361/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9679\n",
      "Epoch 362/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0015 - accuracy: 0.9968 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 363/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0148 - val_accuracy: 0.9678\n",
      "Epoch 364/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0015 - accuracy: 0.9968 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 365/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0015 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9679\n",
      "Epoch 366/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 367/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 368/2000\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0015 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 369/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0146 - val_accuracy: 0.9681\n",
      "Epoch 370/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9679\n",
      "Epoch 371/2000\n",
      "10/10 [==============================] - 2s 155ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9679\n",
      "Epoch 372/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 373/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0015 - accuracy: 0.9968 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 374/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0015 - accuracy: 0.9970 - val_loss: 0.0146 - val_accuracy: 0.9682\n",
      "Epoch 375/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0148 - val_accuracy: 0.9677\n",
      "Epoch 376/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0015 - accuracy: 0.9968 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 377/2000\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 378/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0015 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 379/2000\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0014 - accuracy: 0.9969 - val_loss: 0.0146 - val_accuracy: 0.9682\n",
      "Epoch 380/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 381/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 382/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0146 - val_accuracy: 0.9681\n",
      "Epoch 383/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 384/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 385/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 386/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 387/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 388/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 389/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0148 - val_accuracy: 0.9679\n",
      "Epoch 390/2000\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 391/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 392/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 393/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 394/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 395/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0015 - accuracy: 0.9969 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 396/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 397/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 398/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 399/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 400/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 401/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 402/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 403/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 404/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 405/2000\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 406/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0148 - val_accuracy: 0.9679\n",
      "Epoch 407/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 408/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0148 - val_accuracy: 0.9680\n",
      "Epoch 409/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 410/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9680\n",
      "Epoch 411/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 412/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 413/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0146 - val_accuracy: 0.9683\n",
      "Epoch 414/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 415/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 416/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 417/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 418/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 419/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0148 - val_accuracy: 0.9679\n",
      "Epoch 420/2000\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 421/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 422/2000\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 423/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 424/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9680\n",
      "Epoch 425/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0148 - val_accuracy: 0.9680\n",
      "Epoch 426/2000\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 427/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0148 - val_accuracy: 0.9680\n",
      "Epoch 428/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9680\n",
      "Epoch 429/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 430/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 431/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 432/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9683\n",
      "Epoch 433/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 434/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 435/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 436/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 437/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 438/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 439/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 440/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 441/2000\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9683\n",
      "Epoch 442/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 443/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9680\n",
      "Epoch 444/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9970 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 445/2000\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 446/2000\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 447/2000\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 448/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 449/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 450/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0014 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 451/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0148 - val_accuracy: 0.9680\n",
      "Epoch 452/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 453/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0014 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 454/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0014 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 455/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 456/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 457/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0013 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 458/2000\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 459/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 460/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 461/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 462/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 463/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 464/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 465/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 466/2000\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 467/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 468/2000\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 469/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 470/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 471/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 472/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 473/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0013 - accuracy: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 474/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 475/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 476/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9683\n",
      "Epoch 477/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 478/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9683\n",
      "Epoch 479/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 480/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 481/2000\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 482/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9683\n",
      "Epoch 483/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 484/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 485/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 486/2000\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0013 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 487/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 488/2000\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0013 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 489/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 490/2000\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 491/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 492/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 493/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0013 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 494/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0013 - accuracy: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 495/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0013 - accuracy: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 496/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0013 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 497/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 498/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 499/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0013 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 500/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 501/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0013 - accuracy: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 502/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9681\n",
      "Epoch 503/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 504/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 505/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 506/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 507/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 508/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 509/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 510/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 511/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 512/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 513/2000\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 514/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 515/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 516/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 517/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 518/2000\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 519/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 520/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 521/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 522/2000\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 523/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 524/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 525/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 526/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 527/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 528/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 529/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 530/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 531/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 532/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 533/2000\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 534/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 535/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 536/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 537/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 538/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 539/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 540/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 541/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 542/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 543/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 544/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 545/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 546/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 547/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 548/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9683\n",
      "Epoch 549/2000\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 550/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 551/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 552/2000\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 553/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 554/2000\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 555/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 556/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 557/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 558/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 559/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 560/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 561/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 562/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 563/2000\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0147 - val_accuracy: 0.9683\n",
      "Epoch 564/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 565/2000\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 566/2000\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 567/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 568/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0013 - accuracy: 0.9975 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 569/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 570/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 571/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 572/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 573/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 574/2000\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 575/2000\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 576/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 577/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 578/2000\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 579/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 580/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 581/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 582/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 583/2000\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 584/2000\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 585/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 586/2000\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 587/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 588/2000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9681\n",
      "Epoch 589/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 590/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0147 - val_accuracy: 0.9683\n",
      "Epoch 591/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0147 - val_accuracy: 0.9682\n",
      "Epoch 592/2000\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 593/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 594/2000\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 595/2000\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0013 - accuracy: 0.9974 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Epoch 596/2000\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 0.9975 - val_loss: 0.0148 - val_accuracy: 0.9682\n",
      "Current Time = 20:10:31 Difference 0:16:28.995468\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "with tf.device('/device:gpu:2'):\n",
    "    begin = datetime.now()\n",
    "    current_time = begin.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    #,'mandible-Right-Canine/iteration1','mandible-Right-Canine/iteration2','maxilla-Right-Molar/iteration1'\n",
    "    train_segmentation('segmentation',unet3d(4),['mandible-Right-Molar/iteration1','mandible-Right-Molar/iteration2','mandible-Right-Molar/iteration3','mandible-Right-Molar/iteration4','mandible-Right-Canine/iteration1','mandible-Right-Canine/iteration3','maxilla-Right-Molar/iteration1','maxilla-Right-Molar/iteration2','mandible-Right-Canine/iteration2'])\n",
    "    \n",
    "    end = datetime.now()\n",
    "    current_time = end.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time,\"Difference\",(end-begin))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
