{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jain0000/miniconda3/envs/segment2/lib/python3.7/site-packages/dicom/__init__.py:53: UserWarning: \n",
      "This code is using an older version of pydicom, which is no longer \n",
      "maintained as of Jan 2017.  You can access the new pydicom features and API \n",
      "by installing `pydicom` from PyPI.\n",
      "See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org \n",
      "for more information.\n",
      "\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from niwidgets import NiftiWidget\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"AUTOGRAPH_VERBOSITY\"] = '0'\n",
    "# Verbosity is now 5\n",
    "\n",
    "tf.autograph.set_verbosity(0)\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#import cv2\n",
    "#import random\n",
    "#from skimage.transform import rescale, resize, downscale_local_mean,rotate\n",
    "import numpy as np\n",
    "#from skimage.util import montage, crop\n",
    "#from tensorflow.keras.models import load_model\n",
    "from skimage.transform import rescale, resize, downscale_local_mean,rotate\n",
    "#from skimage import data, color\n",
    "#from scipy import ndimage\n",
    "#from scipy import misc\n",
    "from numpy import fliplr\n",
    "\n",
    "import numpy as np\n",
    "#from skimage.measure import label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from modelIO import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class weighted_bce(Loss):\n",
    "      def call(self, y_true, y_pred, weight1=0.1, weight0=1 ):\n",
    "       # wmap =unet_weight_map(y, wc=None, w0 = 1, sigma = 2)\n",
    "        y_pred = ops.convert_to_tensor_v2(y_pred)\n",
    "        y_true = gen_math_ops.cast(y_true, y_pred.dtype)\n",
    "        y_true = tf.keras.backend.clip(y_true, tf.keras.backend.epsilon(), 1-tf.keras.backend.epsilon())\n",
    "        y_pred = tf.keras.backend.clip(y_pred, tf.keras.backend.epsilon(), 1-tf.keras.backend.epsilon())\n",
    "        logloss = -(y_true * tf.keras.backend.log(y_pred) * weight0 + (1 - y_true) * tf.keras.backend.log(1 - y_pred) * weight1 )\n",
    "        return tf.keras.backend.mean( logloss, axis=-1)\n",
    "    \n",
    "class Dice(Loss):\n",
    "      def call(self, y_true, y_pred, weight1=0.1, weight0=1 ):\n",
    "        y_pred = ops.convert_to_tensor_v2(y_pred)\n",
    "        y_true = gen_math_ops.cast(y_true, y_pred.dtype)\n",
    "        y_true = tf.keras.backend.clip(y_true, tf.keras.backend.epsilon(), 1-tf.keras.backend.epsilon())\n",
    "        y_pred = tf.keras.backend.clip(y_pred, tf.keras.backend.epsilon(), 1-tf.keras.backend.epsilon())\n",
    "        \n",
    "        intersection = tf.keras.backend.sum(tf.keras.backend.abs(y_true * y_pred), axis=-1)\n",
    "        numerator = (2. * intersection + 1) \n",
    "        denominator = (tf.keras.backend.sum(tf.keras.backend.square(y_true),-1) + tf.keras.backend.sum(tf.keras.backend.square(y_pred),-1) + 1)\n",
    "        return 1 - (numerator/denominator)\n",
    "\n",
    "\n",
    "from tensorflow.keras.metrics import MeanIoU,BinaryCrossentropy,Accuracy,Precision,Recall,AUC\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def print_metrics(TestType,mask,pred_mask,model,niiImage ):\n",
    "    \n",
    "   \n",
    "    m2 = AUC()\n",
    "    m2.update_state(mask.flatten(), pred_mask.flatten())\n",
    "\n",
    "    m4 = Accuracy()\n",
    "    m4.update_state(mask.flatten(), pred_mask.flatten())\n",
    "\n",
    "    m5 = Precision()\n",
    "    m5.update_state(mask.flatten(), pred_mask.flatten())\n",
    "\n",
    "    m7 = Recall()\n",
    "    m7.update_state(mask.flatten(), pred_mask.flatten())\n",
    "    \n",
    "    m8 = tf.keras.metrics.FalsePositives()\n",
    "    m8.update_state(mask, pred_mask)\n",
    "    print(\"false positives\",m8.result().numpy())\n",
    "    \n",
    "    m9= tf.keras.metrics.FalseNegatives()\n",
    "    m9.update_state(mask, pred_mask)\n",
    "    print(\"false negatives\",m9.result().numpy())\n",
    "    \n",
    "    m10 = tf.keras.metrics.TruePositives()\n",
    "    m10.update_state(mask, pred_mask)\n",
    "    print(\"true positives\",m10.result().numpy())\n",
    "\n",
    "    m11= tf.keras.metrics.TrueNegatives()\n",
    "    m11.update_state(mask, pred_mask)\n",
    "    print(\"true negatives\",m11.result().numpy())\n",
    "  #  from scipy.spatial.distance import directed_hausdorff\n",
    "  #  m5 = directed_hausdorff(mask, pred_mask)[0]\n",
    "   # m5.update_state(mask.flatten(), pred_mask.flatten())\n",
    "    \n",
    "    m =( 2 *  m10.result().numpy())/ ( m10.result().numpy() + m8.result().numpy() +  m10.result().numpy() +  m9.result().numpy())\n",
    "    m6 = m11.result().numpy()/(m11.result().numpy()+m8.result().numpy())\n",
    "  #  m6.update_state(mask.flatten(), pred_mask.flatten())\n",
    "   # print(\"f1 score\", m7.result().numpy())\n",
    "    \n",
    "    print(\"TestType\",'1',\"DICE\",m,\"Accuracy\",m4.result().numpy(),\"Specificity\",m6,\"AUC\",m2.result().numpy())\n",
    "    \n",
    "     # create logger\n",
    "    #logging.disable(logging.WARNING)    \n",
    "    logging.info(' Test : %s, Model: %s, Type: %s , sample : %s, Accuracy : %s ,DICE : %s , Specificity: %s, AUC: %s','Segmentation2D', TestType,model, niiImage ,m4.result().numpy(),m,\n",
    "         m6,m2.result().numpy())\n",
    "    # define a Handler which writes INFO messages or higher to the sys.stderr\n",
    "    return None\n",
    "\n",
    "def normalizeImageIntensityRange(img):\n",
    "    \n",
    "    img[img < HOUNSFIELD_MIN] = HOUNSFIELD_MIN\n",
    "    img[img > HOUNSFIELD_MAX] = HOUNSFIELD_MAX\n",
    "    return (img - HOUNSFIELD_MIN) / HOUNSFIELD_RANGE\n",
    "def get_largest_component(image):\n",
    "    \"\"\"\n",
    "    get the largest component from 2D or 3D binary image\n",
    "    image: nd array\n",
    "    \"\"\"\n",
    "    dim = len(image.shape)\n",
    "    if(image.sum() == 0 ):\n",
    "        print('the largest component is null')\n",
    "        return image\n",
    "    if(dim == 2):\n",
    "        s = ndimage.generate_binary_structure(2,1)\n",
    "    elif(dim == 3):\n",
    "        s = ndimage.generate_binary_structure(3,1)\n",
    "    else:\n",
    "        raise ValueError(\"the dimension number should be 2 or 3\")\n",
    "    labeled_array, numpatches = ndimage.label(image, s)\n",
    "    sizes = ndimage.sum(image, labeled_array, range(1, numpatches + 1))\n",
    "    max_label = np.where(sizes == sizes.max())[0] + 1\n",
    "    output = np.asarray(labeled_array == max_label, np.double)\n",
    "    return  output \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDirectory = data_dir_test\n",
    "dirs = os.listdir(os.path.join(data_dir_test_image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from skimage.measure import marching_cubes_lewiner\n",
    "import meshplot as mp\n",
    "def test(task,data_type):\n",
    "    #os.listdir(os.path.join(data_dir_test+str('image')))\n",
    "    #dirs = os.listdir(data_dir_train_image)\n",
    "    maskArr=[]\n",
    "    predMaskArr=[]\n",
    "    for d in os.listdir(data_dir_test_image)  :\n",
    "        #if d in ['mandible-Right-Molar','mandible-Right-Canine','maxilla-Right-Molar']:\n",
    "        for niiImage in os.listdir(os.path.join(data_dir_test_image,d)):\n",
    "            model = load('classification')\n",
    "            #model2= load('classification')\n",
    "        #    model3 = load('segmentation/molar')\n",
    "        #    model4= load('segmentation/canine')\n",
    "          #  print(os.path.join(data_dir_test_mask,d, niiImage))\n",
    "           # print(os.path.isfile(os.path.join(data_dir_test_mask,d, niiImage)))\n",
    "            #if(os.path.isfile(os.path.join(data_dir_test_mask,d, niiImage))):\n",
    "            img = nib.load( os.path.join(data_dir_test_image,d, niiImage))\n",
    "           # inputs = normalizeImageIntensityRange(img.get_fdata() ) \n",
    "            print(inputs.shape)\n",
    "            #inputs = exposure.equalize_hist(inputs)\n",
    "            mask = np.round(nib.load( os.path.join(data_dir_test_mask,d, niiImage)).get_fdata()) \n",
    "\n",
    "            print(niiImage)\n",
    "\n",
    "            logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s',\n",
    "                    filename='myapp.log',\n",
    "                    filemode='a')\n",
    "\n",
    "\n",
    "            console = logging.StreamHandler()\n",
    "            console.setLevel(logging.INFO)\n",
    "            # set a format which is simpler for console use\n",
    "            formatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')\n",
    "            # tell the handler to use this format\n",
    "            console.setFormatter(formatter)\n",
    "            # add the handler to the root logger\n",
    "            logging.getLogger('').addHandler(console)\n",
    "\n",
    "           # img_np = np.rollaxis(np.array(np.array([np.array([np.array(inputs)]) ])),0,5)\n",
    "            if task=='segmentation2d':\n",
    "             # print(resize_image.shape)\n",
    "                pred = predictVolume(model,inputs) \n",
    "                #i = resize(pred, (40, 40, 40), anti_aliasing=True)\n",
    "                pred1 = np.rollaxis(np.array(np.array([np.array([np.array(pred)]) ])),0,5)\n",
    "            else:\n",
    "                shape = (IMAGE_HEIGHT, IMAGE_WIDTH,IMAGE_DEPTH)\n",
    "                resize_image = resize(inputs, shape, anti_aliasing=True)\n",
    "                resize_mask = resize(mask, shape, anti_aliasing=True)    \n",
    "                img_np = np.rollaxis(np.array(np.array([np.array([np.array(resize_image)]) ])),0,5)\n",
    "               # @tf.autograph.experimental.do_not_convert\n",
    "                #@tf.autograph.experimental.do_not_convert\n",
    "                predsc = (model.predict(img_np)).astype(float)\n",
    "                pred1 = predsc[0]\n",
    "                \n",
    "                #fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, pred1)\n",
    "            class_no = predsc[1] \n",
    "            print(\"Predicted : \", class_no,\" True class:  \", d )\n",
    "            print(pred1.shape)\n",
    "            pred_mask  = resize_data(pred1[0][:,:,:,0],mask.shape) \n",
    "            \n",
    "           # y=pred_mask\n",
    "         #   y = get_largest_component(np.round(pred_mask))\n",
    "        #    img = nib.Nifti1Image(y,  img.affine)\n",
    "         #   if os.path.isdir(os.path.join(data_dir_test,'segmented-volume',d)):\n",
    "       #         nib.save(img, os.path.join(data_dir_test,'segmented-volume',d, niiImage))  \n",
    "       #     else:\n",
    "       #         directory = os.mkdir(os.path.join(data_dir_test,'segmented-volume',d))\n",
    "       #         nib.save(img, os.path.join(data_dir_test,'segmented-volume',d, niiImage))  \n",
    "\n",
    "            #y = get_largest_component(np.round(pred_mask))\n",
    "           # maskArr.append(mask)\n",
    "           # predMaskArr.append(y)\n",
    "         #   x = print_metrics('Sparse',mask,(y),str(d),niiImage)\n",
    "\n",
    "          #  display(inputs,pred_mask)\n",
    "         #   vertices,faces,_,_ = marching_cubes_lewiner(y)\n",
    "\n",
    "        #    mp.plot(vertices, faces, return_plot=False)\n",
    "    \n",
    "    \n",
    "        #    from sklearn.metrics import roc_curve\n",
    "           # print(roc_curve(mask.flatten(), y.flatten()))\n",
    "          #  fpr_keras, tpr_keras, thresholds_keras =(np.array([0.        , 0.00239111, 1.        ]), np.array([0.        , 0.90658531, 1.        ]), np.array([2., 1., 0.]))\n",
    "\n",
    " #roc_curve(mask.flatten(), y.flatten())\n",
    "          #  from sklearn.metrics import auc\n",
    "        #    auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "        #    plt.figure(1)\n",
    "        #    plt.plot([0, 1], [0, 1], 'k--')\n",
    "       #     plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "       #     plt.xlabel('False positive rate')\n",
    "       #     plt.ylabel('True positive rate')\n",
    "       #     plt.title('AUC curve')\n",
    "       #     plt.legend(loc='best')\n",
    "       #     plt.show()\n",
    "    \n",
    "    return (img,pred_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "with tf.device('/device:gpu:2'):\n",
    "    test('classification',['mandible-Right-Molar','mandible-Right-Canine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
